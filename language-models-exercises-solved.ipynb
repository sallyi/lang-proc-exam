{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This function gets a list as input and returns the product of all numbers in the list.\n",
    "def prod (ite):\n",
    "    if len(ite)==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return ite[0]*prod(ite[1:])\n",
    "prod ([2,7,3]) #2 x 7 x 3 = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - What is the difference between the following two lines? Which one will give a larger value? Will this be the case for other texts?\n",
    " \n",
    "`>>> sorted(set([w.lower() for w in text1]))`\n",
    "\n",
    "`>>> sorted([w.lower() for w in set(text1)])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1= \"a a b a A b a\".split()\n",
    "sorted(set([w.lower() for w in text1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'b']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([w.lower() for w in set(text1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "blake_poems = gutenberg.sents(\"blake-poems.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Print the first 10 sentences of the text. Print them well formatated, not just printing the list.\n",
    " \n",
    " ~~`print (blake_poems)`~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Poems by William Blake 1789 ]\n",
      "SONGS OF INNOCENCE AND OF EXPERIENCE and THE BOOK of THEL\n",
      "SONGS OF INNOCENCE\n",
      "INTRODUCTION\n",
      "Piping down the valleys wild , Piping songs of pleasant glee , On a cloud I saw a child , And he laughing said to me :\n",
      "\" Pipe a song about a Lamb !\"\n",
      "So I piped with merry cheer .\n",
      "\" Piper , pipe that song again ;\" So I piped : he wept to hear .\n",
      "\" Drop thy pipe , thy happy pipe ; Sing thy songs of happy cheer :!\"\n",
      "So I sang the same again , While he wept with joy to hear .\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "print ('\\n'.join([' '.join(sent) for sent in blake_poems][:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language modeling exercises\n",
    "\n",
    "Go through the documentation of NLTK and check how bigrams, trigrams or n-grams calculators work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function bigrams in module nltk.util:\n",
      "\n",
      "bigrams(sequence, **kwargs)\n",
      "    Return the bigrams generated from a sequence of items, as an iterator.\n",
      "    For example:\n",
      "    \n",
      "        >>> from nltk.util import bigrams\n",
      "        >>> list(bigrams([1,2,3,4,5]))\n",
      "        [(1, 2), (2, 3), (3, 4), (4, 5)]\n",
      "    \n",
      "    Use bigrams for a list version of this function.\n",
      "    \n",
      "    :param sequence: the source data to be converted into bigrams\n",
      "    :type sequence: sequence or iter\n",
      "    :rtype: iter(tuple)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take the example from the slides, and let's calculate the frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> I am Sam </s>\\n<s> Sam I am </s>\\n<s> I like eggs </s>\\n<s> I do not like green eggs and ham </s>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus1 = \"\"\"<s> I am Sam </s>\n",
    "<s> Sam I am </s>\n",
    "<s> I like eggs </s>\n",
    "<s> I do not like green eggs and ham </s>\"\"\"\n",
    "corpus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Sam',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'Sam',\n",
       " 'I',\n",
       " 'am',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'I',\n",
       " 'like',\n",
       " 'eggs',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'I',\n",
       " 'do',\n",
       " 'not',\n",
       " 'like',\n",
       " 'green',\n",
       " 'eggs',\n",
       " 'and',\n",
       " 'ham',\n",
       " '</s>']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=corpus1.split()\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Frequencies\n",
    "\n",
    "Now we want to see which are the common words that come after another word. We will combine `nltk.bigrams` and `nltk.ConditionalFreqDist` in order to get it.\n",
    "\n",
    "Please check the documentation, and get the conditional frequencies of our toy corpus (`corpus1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConditionalFreqDist with 12 conditions>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "cfreq_corpus1_bigrams= nltk.ConditionalFreqDist(nltk.bigrams(words))\n",
    "cfreq_corpus1_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - What is common to observe after the word \"I\"? How often do those words occur? Check that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'am': 2, 'like': 1, 'do': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "cfreq_corpus1_bigrams['I']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We all know that we can't draw conclusions from only frequencies. There are some words (usually connectors) that appear much more often tham others.\n",
    "\n",
    "But, we need to normalize all those figures that we have. Because of that, we will calculate conditional probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional probabilities\n",
    "\n",
    "Instead of checking just the frequency distributions, now you will build a set of probability distributions for each word in the corpus. You have to do it in a similar way, using the `nltk.ConditionalProbDist` class. Check the documentation and play with it. You can also check chapter 2.2 at the NLTK book (Bird and others, 2009)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "#help(nltk.ConditionalProbDist)\n",
    "cprob_corpus1_bigrams = nltk.ConditionalProbDist(cfreq_corpus1_bigrams, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence's probability\n",
    "\n",
    "You may calculate the probability of a sentence by multiplying the different conditional probabilities in the sentence. Then, we want to calculate the probability of the following sentence:\n",
    "\n",
    "`I like green eggs`\n",
    "\n",
    "We want to calculate the whole sentences probability,\n",
    "\n",
    "$P(<s>, I, like, green, eggs, </s>)$\n",
    "\n",
    "which, by using the Markov property, we can model the sentence as\n",
    "\n",
    "$P(<s>, I, like, green, eggs, </s>) = $\n",
    "\n",
    "$P(I | <s>) * P(like | I) * P(green | like) * P(eggs | green) * P(</s> | eggs)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046875"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "example = \"I like green eggs\"\n",
    "example = \"<s> \" + example + \" </s>\"\n",
    "example_list = example.split()\n",
    "prod([cprob_corpus1_bigrams[bigram[0]].prob(bigram[1]) for bigram in nltk.bigrams(example_list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final exercise\n",
    "\n",
    "Now, you learned about how to create simple language models. The goal now is to see how can we use them in real life. Language models are been used in the last years for a wide variety of topics.\n",
    "\n",
    "In this last exercise we will do something similar. You will have to get two texts from project gutenberg:\n",
    "\n",
    " - Alice's adventures in Wonderland: 'carroll-alice.txt'\n",
    " \n",
    " - Shakespeare's Hamlet: 'shakespeare-hamlet.txt'\n",
    " \n",
    "Calculate separate bigram language models and then find out some sentences that are more probable for one author or another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "alice = gutenberg.sents(\"carroll-alice.txt\")\n",
    "hamlet = gutenberg.sents(\"shakespeare-hamlet.txt\")\n",
    "\n",
    "#Create a LM for Alice's Adventures in Wonderland\n",
    "alice_wbounds = [[\"<s>\"]+sentence+[\"</s>\"] for sentence in alice]\n",
    "alice_words = [word for sentence in alice_wbounds for word in sentence]\n",
    "cfreq_alice_bigrams= nltk.ConditionalFreqDist(nltk.bigrams(alice_words))\n",
    "cprob_alice_bigrams = nltk.ConditionalProbDist(cfreq_alice_bigrams, nltk.MLEProbDist)\n",
    "\n",
    "#Create a LM for Shakespeare's Hamlet\n",
    "hamlet_wbounds = [[\"<s>\"]+sentence+[\"</s>\"] for sentence in hamlet]\n",
    "hamlet_words = [word for sentence in hamlet_wbounds for word in sentence]\n",
    "cfreq_hamlet_bigrams= nltk.ConditionalFreqDist(nltk.bigrams(hamlet_words))\n",
    "cprob_hamlet_bigrams = nltk.ConditionalProbDist(cfreq_hamlet_bigrams, nltk.MLEProbDist)\n",
    "\n",
    "def prob_bigram_lm(sent, lm):\n",
    "    sent_wb = \"<s> \" + sent + \" </s>\"\n",
    "    return prod([lm[bigram[0]].prob(bigram[1]) for bigram in nltk.bigrams(sent_wb.split())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046875"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_bigram_lm(\"I like green eggs\", cprob_corpus1_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5777924772206303e-09"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_bigram_lm(\"She was sitting on the hedge .\", cprob_alice_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I tried to look for an example that would be non-zero in both books, but it's hard.\n",
    "#If you find an example that could work, please tell me :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Furthermore\n",
    "\n",
    "Are you bored? Test these models but using single letters as units instead of whole words. With letters you will be able to build a quite successful language identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
