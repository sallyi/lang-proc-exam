{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "\n",
    "In this notebook we will learn how to extract different features from a text and how to combine them. It's pretty simple, but if you have this part well organized, it will be really useful in the near future. So, let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T10:26:57.955820Z",
     "start_time": "2019-05-05T10:26:48.977623Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T10:26:57.968032Z",
     "start_time": "2019-05-05T10:26:57.962576Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sentences = [\n",
    "    'I liked this movie',\n",
    "    'The plot was intriguing',\n",
    "    'Oh, it was truly boring',\n",
    "]\n",
    "train_classes = [1,1,0]\n",
    "\n",
    "test_sentences = [\n",
    "    'I liked it',\n",
    "    'The plot was boring !',\n",
    "    'Oh, it was absolutely terrible !',\n",
    "]\n",
    "test_classes = [1,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Get the bag of words representation of the training set\n",
    "\n",
    "You can make it simply by using the `CountVectorizer` class from `scikit-learn`. Once you instantiate the vectorizer and you `fit_transform` it, this should create a 3x11 sparse matrix.\n",
    "\n",
    "If the matrix is saved in a variable called `X`, you can see the values of the matrix by using the `X.toarray()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#help(CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Now get a bag of words of bigrams and trigrams from the training set\n",
    "\n",
    "Use the same class as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hint:\n",
    "\n",
    "Oh, do you want to check the vocabulary of the training set? You can do it using the vectorizer. If the vectorizer is saved in a variable called `unigram_vectorizer`, you can check the attribute `unigram_vectorizer.vocabulary_` and you will see the vocabulary there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Test these vectorizers with the test set\n",
    "\n",
    "Try the vectorizers with the test set. What happens if a word doesn't appear in the training corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Calculate bag of postags for the training set and then apply the vectorizer on the test set.\n",
    "\n",
    "Calculate something similar to the bag of words, but instead of using the words, use the POS-tags of the sentences. The goal here is not to get perfect results, so then, use the `nltk.pos_tag()` function to get the part-of-speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Combine all features for each sentence.\n",
    "\n",
    "Combine all the previous features, and generate a matrix encoding all previously mentioned features: unigrams, bigrams, trigrams and pos_tags. The resulting matrix should have the following dimensions: 3x31\n",
    "\n",
    "You could use the `sklearn.pipeline.FeatureUnion` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra to play with: Check this website and think about it. Do you think you can use this for something? (in the exam)\n",
    "\n",
    "http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHARE YOUR KNOWLEDGE!\n",
    "\n",
    "### Do you know any other way of representing the features of the training/testing set?\n",
    "\n",
    "Please share your knowledge using the forum from Absalon!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
