{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This function gets a list as input and returns the product of all numbers in the list.\n",
    "def prod (ite):\n",
    "    if len(ite)==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return ite[0]*prod(ite[1:])\n",
    "prod ([2,7,3]) #2 x 7 x 3 = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - What is the difference between the following two lines? Which one will give a larger value? Will this be the case for other texts?\n",
    " \n",
    "`>>> sorted(set([w.lower() for w in text1]))`\n",
    "\n",
    "`>>> sorted([w.lower() for w in set(text1)])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[', 'Poems', 'by', 'William', 'Blake', '1789', ']'], ['SONGS', 'OF', 'INNOCENCE', 'AND', 'OF', 'EXPERIENCE', 'and', 'THE', 'BOOK', 'of', 'THEL'], ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blake_poems = gutenberg.sents(\"blake-poems.txt\")\n",
    "blake_poems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Print the first 10 sentences of the text. Print them well formatated, not just printing the list.\n",
    " \n",
    " ~~`print (blake_poems)`~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Poems by William Blake 1789 ]\n",
      "SONGS OF INNOCENCE AND OF EXPERIENCE and THE BOOK of THEL\n",
      "SONGS OF INNOCENCE\n",
      "INTRODUCTION\n",
      "Piping down the valleys wild , Piping songs of pleasant glee , On a cloud I saw a child , And he laughing said to me :\n",
      "\" Pipe a song about a Lamb !\"\n",
      "So I piped with merry cheer .\n",
      "\" Piper , pipe that song again ;\" So I piped : he wept to hear .\n",
      "\" Drop thy pipe , thy happy pipe ; Sing thy songs of happy cheer :!\"\n",
      "So I sang the same again , While he wept with joy to hear .\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "for i, sent in enumerate(blake_poems):\n",
    "    if i < 10:\n",
    "        print(' '.join([word for word in sent]).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language modeling exercises\n",
    "\n",
    "Go through the documentation of NLTK and check how bigrams, trigrams or n-grams calculators work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function ngrams in module nltk.util:\n",
      "\n",
      "ngrams(sequence, n, pad_left=False, pad_right=False, left_pad_symbol=None, right_pad_symbol=None)\n",
      "    Return the ngrams generated from a sequence of items, as an iterator.\n",
      "    For example:\n",
      "    \n",
      "        >>> from nltk.util import ngrams\n",
      "        >>> list(ngrams([1,2,3,4,5], 3))\n",
      "        [(1, 2, 3), (2, 3, 4), (3, 4, 5)]\n",
      "    \n",
      "    Wrap with list for a list version of this function.  Set pad_left\n",
      "    or pad_right to true in order to get additional ngrams:\n",
      "    \n",
      "        >>> list(ngrams([1,2,3,4,5], 2, pad_right=True))\n",
      "        [(1, 2), (2, 3), (3, 4), (4, 5), (5, None)]\n",
      "        >>> list(ngrams([1,2,3,4,5], 2, pad_right=True, right_pad_symbol='</s>'))\n",
      "        [(1, 2), (2, 3), (3, 4), (4, 5), (5, '</s>')]\n",
      "        >>> list(ngrams([1,2,3,4,5], 2, pad_left=True, left_pad_symbol='<s>'))\n",
      "        [('<s>', 1), (1, 2), (2, 3), (3, 4), (4, 5)]\n",
      "        >>> list(ngrams([1,2,3,4,5], 2, pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='</s>'))\n",
      "        [('<s>', 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, '</s>')]\n",
      "    \n",
      "    \n",
      "    :param sequence: the source data to be converted into ngrams\n",
      "    :type sequence: sequence or iter\n",
      "    :param n: the degree of the ngrams\n",
      "    :type n: int\n",
      "    :param pad_left: whether the ngrams should be left-padded\n",
      "    :type pad_left: bool\n",
      "    :param pad_right: whether the ngrams should be right-padded\n",
      "    :type pad_right: bool\n",
      "    :param left_pad_symbol: the symbol to use for left padding (default is None)\n",
      "    :type left_pad_symbol: any\n",
      "    :param right_pad_symbol: the symbol to use for right padding (default is None)\n",
      "    :type right_pad_symbol: any\n",
      "    :rtype: sequence or iter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take the example from the slides, and let's calculate the frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> I am Sam </s>\\n<s> Sam I am </s>\\n<s> I like Sally </s>\\n<s> I do not like green eggs and ham </s>\\n<s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus1 = \"\"\"<s> I am Sam </s>\n",
    "<s> Sam I am </s>\n",
    "<s> I like Sally </s>\n",
    "<s> I do not like green eggs and ham </s>\n",
    "<s>\"\"\"\n",
    "corpus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Sam',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'Sam',\n",
       " 'I',\n",
       " 'am',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'I',\n",
       " 'like',\n",
       " 'Sally',\n",
       " '</s>',\n",
       " '<s>',\n",
       " 'I',\n",
       " 'do',\n",
       " 'not',\n",
       " 'like',\n",
       " 'green',\n",
       " 'eggs',\n",
       " 'and',\n",
       " 'ham',\n",
       " '</s>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=corpus1.split()\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Frequencies\n",
    "\n",
    "Now we want to see which are the common words that come after another word. We will combine `nltk.bigrams` and `nltk.ConditionalFreqDist` in order to get it.\n",
    "\n",
    "Please check the documentation, and get the conditional frequencies of our toy corpus (`corpus1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('<s>', FreqDist({'I': 3, 'Sam': 1})), ('I', FreqDist({'am': 2, 'like': 1, 'do': 1})), ('am', FreqDist({'Sam': 1, '</s>': 1})), ('Sam', FreqDist({'</s>': 1, 'I': 1})), ('</s>', FreqDist({'<s>': 3})), ('like', FreqDist({'Sally': 1, 'green': 1})), ('Sally', FreqDist({'</s>': 1})), ('do', FreqDist({'not': 1})), ('not', FreqDist({'like': 1})), ('green', FreqDist({'eggs': 1})), ('eggs', FreqDist({'and': 1})), ('and', FreqDist({'ham': 1})), ('ham', FreqDist({'</s>': 1}))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "cfdist = nltk.ConditionalFreqDist(bigram for bigram in nltk.bigrams(words))\n",
    "cfdist.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - What is common to observe after the word \"I\"? How often do those words occur? Check that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'am': 2, 'like': 1, 'do': 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfdist['I']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We all know that we can't draw conclusions from only frequencies. There are some words (usually connectors) that appear much more often tham others.\n",
    "\n",
    "But, we need to normalize all those figures that we have. Because of that, we will calculate conditional probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional probabilities\n",
    "\n",
    "Instead of checking just the frequency distributions, now you will build a set of probability distributions for each word in the corpus. You have to do it in a similar way, using the `nltk.ConditionalProbDist` class. Check the documentation and play with it. You can also check chapter 2.2 at the NLTK book (Bird and others, 2009)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import ConditionalProbDist, ELEProbDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConditionalProbDist with 13 conditions>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpdist = ConditionalProbDist(cfdist, ELEProbDist, 10)\n",
    "cpdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('<s>', <ELEProbDist based on 4 samples>), ('I', <ELEProbDist based on 4 samples>), ('am', <ELEProbDist based on 2 samples>), ('Sam', <ELEProbDist based on 2 samples>), ('</s>', <ELEProbDist based on 3 samples>), ('like', <ELEProbDist based on 2 samples>), ('Sally', <ELEProbDist based on 1 samples>), ('do', <ELEProbDist based on 1 samples>), ('not', <ELEProbDist based on 1 samples>), ('green', <ELEProbDist based on 1 samples>), ('eggs', <ELEProbDist based on 1 samples>), ('and', <ELEProbDist based on 1 samples>), ('ham', <ELEProbDist based on 1 samples>)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpdist.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpdist['I'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2777777777777778"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpdist['I'].prob('am')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpdist['I'].prob('do')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence's probability\n",
    "\n",
    "You may calculate the probability of a sentence by multiplying the different conditional probabilities in the sentence. Then, we want to calculate the probability of the following sentence:\n",
    "\n",
    "`I like green eggs`\n",
    "\n",
    "We want to calculate the whole sentences probability,\n",
    "\n",
    "$P(<s>, I, like, green, eggs, </s>)$\n",
    "\n",
    "which, by using the Markov property, we can model the sentence as\n",
    "\n",
    "$P(<s>, I, like, green, eggs, </s>) = $\n",
    "\n",
    "$P(I | <s>) * P(like | I) * P(green | like) * P(eggs | green) * P(</s> | eggs)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00028935185185185184"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "cpdist['<s>'].prob('I') * cpdist['I'].prob('like') * cpdist['like'].prob('green') * cpdist['green'].prob('eggs') * cpdist['eggs'].prob('</s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConditionalFreqDist with 13 conditions>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#YOUR CODE HERE\n",
    "cfreq_corpus1_bigrams= nltk.ConditionalFreqDist(nltk.bigrams(words))\n",
    "cfreq_corpus1_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "#help(nltk.ConditionalProbDist)\n",
    "cprob_corpus1_bigrams = nltk.ConditionalProbDist(cfreq_corpus1_bigrams, nltk.MLEProbDist)\n",
    "#YOUR CODE HERE\n",
    "example = \"I like green eggs\"\n",
    "example = \"<s> \" + example + \" </s> <s>\"\n",
    "example_list = example.split()\n",
    "prod([cprob_corpus1_bigrams[bigram[0]].prob(bigram[1]) for bigram in nltk.bigrams(example_list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final exercise\n",
    "\n",
    "Now, you learned about how to create simple language models. The goal now is to see how can we use them in real life. Language models are been used in the last years for a wide variety of topics.\n",
    "\n",
    "In this last exercise we will do something similar. You will have to get two texts from project gutenberg:\n",
    "\n",
    " - Alice's adventures in Wonderland: 'carroll-alice.txt'\n",
    " \n",
    " - Shakespeare's Hamlet: 'shakespeare-hamlet.txt'\n",
    " \n",
    "Calculate separate bigram language models and then find out some word sequences that are more probable for one author or another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Furthermore\n",
    "\n",
    "Are you bored? Test these models but using single letters as units instead of whole words. With letters you will be able to build a quite successful language identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
