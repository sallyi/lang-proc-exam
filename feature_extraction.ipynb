{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "\n",
    "In this notebook we will learn how to extract different features from a text and how to combine them. It's pretty simple, but if you have this part well organized, it will be really useful in the near future. So, let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "import codecs\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sallyisa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sallyisa/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7x31 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 184 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def get_pos_ngrams(sents):\n",
    "    pos_tags= [nltk.pos_tag(word_tokenize(sents[ind])) for ind, item in enumerate(sents) if item != '']\n",
    "\n",
    "    pos_sents = []\n",
    "    for sent in pos_tags:\n",
    "        pos = ' '.join([pos_tag[1] for pos_tag in sent])\n",
    "        pos_sents.append(pos)\n",
    "\n",
    "    vectorizer = CountVectorizer(ngram_range = (1,1),token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\", min_df=1)\n",
    "\n",
    "    pos_ngram = vectorizer.fit_transform(pos_sents)\n",
    "    pos_ngram.toarray(), pos_tags\n",
    "    return pos_ngram\n",
    "\n",
    "get_pos_ngrams(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'gr': 7,\n",
       "             'ra': 6,\n",
       "             'ac': 10,\n",
       "             'ce': 16,\n",
       "             'ef': 5,\n",
       "             'fu': 11,\n",
       "             'ul': 8,\n",
       "             'l ': 9,\n",
       "             ' o': 29,\n",
       "             'on': 25,\n",
       "             'ne': 27,\n",
       "             'es': 13,\n",
       "             's.': 4,\n",
       "             '.\\n': 18,\n",
       "             '\\n\\n': 34,\n",
       "             '\\n\"': 9,\n",
       "             '\"O': 1,\n",
       "             'On': 1,\n",
       "             'e ': 131,\n",
       "             ' m': 20,\n",
       "             'mo': 6,\n",
       "             'or': 26,\n",
       "             're': 41,\n",
       "             'e,': 9,\n",
       "             ',\"': 6,\n",
       "             '\" ': 8,\n",
       "             ' M': 7,\n",
       "             'Ma': 11,\n",
       "             'ar': 27,\n",
       "             'rv': 11,\n",
       "             've': 27,\n",
       "             'el': 28,\n",
       "             'lo': 22,\n",
       "             'ou': 44,\n",
       "             'us': 28,\n",
       "             's ': 68,\n",
       "             ' s': 72,\n",
       "             'sa': 13,\n",
       "             'ai': 18,\n",
       "             'id': 12,\n",
       "             'd,': 13,\n",
       "             ', ': 42,\n",
       "             'so': 5,\n",
       "             'un': 9,\n",
       "             'nd': 46,\n",
       "             'di': 6,\n",
       "             'in': 76,\n",
       "             'ng': 49,\n",
       "             'g ': 39,\n",
       "             ' r': 9,\n",
       "             'ro': 17,\n",
       "             'oy': 1,\n",
       "             'ya': 4,\n",
       "             'al': 7,\n",
       "             'll': 12,\n",
       "             'ly': 11,\n",
       "             'y ': 17,\n",
       "             ' b': 30,\n",
       "             'bo': 6,\n",
       "             'ed': 46,\n",
       "             'd ': 90,\n",
       "             ' f': 32,\n",
       "             'fr': 2,\n",
       "             'om': 6,\n",
       "             'm ': 8,\n",
       "             ' h': 76,\n",
       "             'hi': 24,\n",
       "             'is': 13,\n",
       "             'se': 18,\n",
       "             'ea': 29,\n",
       "             'at': 39,\n",
       "             't.': 5,\n",
       "             '\"S': 1,\n",
       "             'Sh': 6,\n",
       "             'he': 124,\n",
       "             'e’': 9,\n",
       "             '’s': 12,\n",
       "             ' t': 102,\n",
       "             'ti': 13,\n",
       "             'ir': 9,\n",
       "             ' J': 11,\n",
       "             'Jo': 12,\n",
       "             'oe': 12,\n",
       "             'th': 64,\n",
       "             'ho': 8,\n",
       "             'ug': 6,\n",
       "             'gh': 12,\n",
       "             'h ': 15,\n",
       "             ' n': 17,\n",
       "             'no': 11,\n",
       "             'ot': 12,\n",
       "             't ': 75,\n",
       "             ' u': 13,\n",
       "             'nk': 1,\n",
       "             'ki': 15,\n",
       "             'dl': 3,\n",
       "             'y.': 3,\n",
       "             '. ': 22,\n",
       "             ' (': 3,\n",
       "             '(t': 3,\n",
       "             'uc': 9,\n",
       "             'ck': 14,\n",
       "             ' j': 7,\n",
       "             'je': 2,\n",
       "             'er': 62,\n",
       "             'rk': 4,\n",
       "             'k)': 1,\n",
       "             ').': 1,\n",
       "             '\\nH': 2,\n",
       "             'He': 6,\n",
       "             ' w': 49,\n",
       "             'wa': 25,\n",
       "             'as': 28,\n",
       "             'ri': 7,\n",
       "             'ig': 8,\n",
       "             'ht': 10,\n",
       "             't;': 1,\n",
       "             '; ': 2,\n",
       "             'r ': 56,\n",
       "             'mu': 2,\n",
       "             'sc': 1,\n",
       "             'cl': 2,\n",
       "             'le': 14,\n",
       "             'ha': 22,\n",
       "             'av': 6,\n",
       "             ' l': 19,\n",
       "             'si': 5,\n",
       "             'nc': 8,\n",
       "             'tu': 2,\n",
       "             'ur': 6,\n",
       "             'rn': 4,\n",
       "             'to': 44,\n",
       "             'o ': 43,\n",
       "             ' c': 16,\n",
       "             'co': 8,\n",
       "             'tt': 9,\n",
       "             'n ': 36,\n",
       "             'wi': 10,\n",
       "             'it': 22,\n",
       "             ' e': 18,\n",
       "             'ex': 6,\n",
       "             'xh': 1,\n",
       "             'au': 6,\n",
       "             'st': 20,\n",
       "             'io': 4,\n",
       "             ' a': 76,\n",
       "             'an': 49,\n",
       "             ' k': 7,\n",
       "             'kn': 2,\n",
       "             'ee': 9,\n",
       "             'su': 4,\n",
       "             'up': 8,\n",
       "             'pp': 6,\n",
       "             'po': 4,\n",
       "             'rt': 4,\n",
       "             'pr': 7,\n",
       "             ' B': 2,\n",
       "             'Bu': 2,\n",
       "             'ut': 9,\n",
       "             ' d': 15,\n",
       "             'da': 5,\n",
       "             'am': 3,\n",
       "             'mn': 3,\n",
       "             ' i': 35,\n",
       "             'if': 10,\n",
       "             'f ': 27,\n",
       "             'sh': 31,\n",
       "             ' g': 18,\n",
       "             'go': 8,\n",
       "             'oi': 8,\n",
       "             'ta': 11,\n",
       "             'ak': 5,\n",
       "             'ke': 9,\n",
       "             'of': 14,\n",
       "             'ff': 4,\n",
       "             'fe': 6,\n",
       "             'lp': 1,\n",
       "             'p ': 9,\n",
       "             'p,': 1,\n",
       "             'ma': 9,\n",
       "             'rs': 8,\n",
       "             'lf': 5,\n",
       "             'oo': 16,\n",
       "             'ok': 6,\n",
       "             'k ': 9,\n",
       "             'li': 11,\n",
       "             'ik': 3,\n",
       "             'a ': 19,\n",
       "             'we': 6,\n",
       "             'kl': 1,\n",
       "             'nt': 9,\n",
       "             's,': 3,\n",
       "             'wh': 10,\n",
       "             ' -': 4,\n",
       "             '- ': 4,\n",
       "             'et': 12,\n",
       "             'ca': 8,\n",
       "             'ap': 6,\n",
       "             'pt': 2,\n",
       "             'n.': 3,\n",
       "             '\\nL': 4,\n",
       "             'Lu': 8,\n",
       "             'uk': 8,\n",
       "             'ka': 8,\n",
       "             'de': 11,\n",
       "             'te': 23,\n",
       "             'rm': 3,\n",
       "             'mi': 2,\n",
       "             ' p': 15,\n",
       "             'ov': 4,\n",
       "             'wo': 9,\n",
       "             'em': 4,\n",
       "             'm,': 2,\n",
       "             'k.': 2,\n",
       "             '\\nS': 5,\n",
       "             'So': 1,\n",
       "             'sl': 2,\n",
       "             'la': 11,\n",
       "             'pe': 9,\n",
       "             'aw': 6,\n",
       "             'ay': 10,\n",
       "             'pu': 3,\n",
       "             'fl': 1,\n",
       "             'r,': 2,\n",
       "             'im': 11,\n",
       "             'me': 16,\n",
       "             'sw': 4,\n",
       "             'rd': 6,\n",
       "             'ec': 7,\n",
       "             'k,': 1,\n",
       "             'il': 8,\n",
       "             'be': 19,\n",
       "             'tr': 7,\n",
       "             'r.': 3,\n",
       "             '\"T': 2,\n",
       "             'Th': 5,\n",
       "             'hr': 5,\n",
       "             ' v': 3,\n",
       "             'vo': 2,\n",
       "             'ic': 4,\n",
       "             'mb': 1,\n",
       "             'bl': 5,\n",
       "             'g,': 2,\n",
       "             'sp': 6,\n",
       "             'sm': 3,\n",
       "             '\\nM': 4,\n",
       "             ' y': 12,\n",
       "             'wn': 2,\n",
       "             'd.': 6,\n",
       "             '\\n(': 4,\n",
       "             '(f': 3,\n",
       "             'ks': 2,\n",
       "             'm.': 3,\n",
       "             '.)': 4,\n",
       "             ')\\n': 4,\n",
       "             '\\n-': 1,\n",
       "             '-\\n': 1,\n",
       "             '\\nA': 1,\n",
       "             'A ': 1,\n",
       "             'ew': 3,\n",
       "             'w ': 4,\n",
       "             'ek': 1,\n",
       "             'ei': 7,\n",
       "             'ni': 7,\n",
       "             ' L': 6,\n",
       "             'iz': 1,\n",
       "             'ze': 1,\n",
       "             'ju': 4,\n",
       "             'od': 5,\n",
       "             '\"Y': 2,\n",
       "             'Yo': 5,\n",
       "             'u ': 4,\n",
       "             'ow': 8,\n",
       "             'ad': 10,\n",
       "             'yo': 10,\n",
       "             'op': 4,\n",
       "             'en': 23,\n",
       "             't’': 3,\n",
       "             'ts': 2,\n",
       "             'ci': 2,\n",
       "             'ip': 2,\n",
       "             'pa': 3,\n",
       "             'xt': 4,\n",
       "             'nb': 1,\n",
       "             'br': 2,\n",
       "             'mp': 2,\n",
       "             'ie': 3,\n",
       "             'w.': 3,\n",
       "             '(m': 1,\n",
       "             'yb': 1,\n",
       "             'dn': 5,\n",
       "             'n’': 9,\n",
       "             '’t': 9,\n",
       "             'n,': 3,\n",
       "             'ld': 6,\n",
       "             '’d': 3,\n",
       "             'bu': 3,\n",
       "             'ms': 3,\n",
       "             'os': 4,\n",
       "             'lt': 4,\n",
       "             'gu': 2,\n",
       "             'ui': 1,\n",
       "             'ty': 2,\n",
       "             'fo': 14,\n",
       "             'ol': 1,\n",
       "             'ey': 2,\n",
       "             'ye': 2,\n",
       "             ' “': 11,\n",
       "             '“Y': 3,\n",
       "             'u’': 6,\n",
       "             '’r': 6,\n",
       "             'lk': 2,\n",
       "             'ch': 7,\n",
       "             'h,': 3,\n",
       "             ',”': 2,\n",
       "             '” ': 3,\n",
       "             'rg': 1,\n",
       "             'ge': 8,\n",
       "             'oc': 2,\n",
       "             'ba': 3,\n",
       "             'fa': 3,\n",
       "             'ag': 5,\n",
       "             'ga': 4,\n",
       "             ' T': 1,\n",
       "             'ss': 3,\n",
       "             'cu': 1,\n",
       "             'ua': 1,\n",
       "             'ru': 4,\n",
       "             'ab': 5,\n",
       "             'e.': 11,\n",
       "             ' H': 4,\n",
       "             'pl': 6,\n",
       "             'pi': 2,\n",
       "             'nl': 2,\n",
       "             'rp': 1,\n",
       "             'ns': 3,\n",
       "             't)': 1,\n",
       "             ') ': 2,\n",
       "             '“I': 5,\n",
       "             'I’': 6,\n",
       "             '’m': 5,\n",
       "             'eg': 4,\n",
       "             'gi': 2,\n",
       "             'nn': 3,\n",
       "             'y,': 1,\n",
       "             'a,': 1,\n",
       "             'tc': 3,\n",
       "             '.”': 6,\n",
       "             '”\\n': 8,\n",
       "             'u.': 3,\n",
       "             '\\nJ': 1,\n",
       "             'ja': 1,\n",
       "             'ds': 3,\n",
       "             'gt': 1,\n",
       "             'fi': 6,\n",
       "             'cr': 2,\n",
       "             'ue': 1,\n",
       "             'h.': 3,\n",
       "             '\"I': 1,\n",
       "             'I ': 4,\n",
       "             'dg': 1,\n",
       "             ' \"': 2,\n",
       "             ' Z': 1,\n",
       "             'Za': 1,\n",
       "             'gy': 1,\n",
       "             'rc': 1,\n",
       "             'ev': 6,\n",
       "             'ry': 2,\n",
       "             ' S': 1,\n",
       "             ' I': 5,\n",
       "             'If': 1,\n",
       "             '.\"': 2,\n",
       "             'gg': 1,\n",
       "             '\"M': 1,\n",
       "             'Mi': 1,\n",
       "             'eh': 1,\n",
       "             'p.': 1,\n",
       "             '\"\\n': 3,\n",
       "             '“A': 1,\n",
       "             'Ar': 2,\n",
       "             'yi': 5,\n",
       "             'k?': 1,\n",
       "             '?”': 2,\n",
       "             '\"A': 1,\n",
       "             'u?': 1,\n",
       "             '?\"': 2,\n",
       "             'wr': 1,\n",
       "             '’l': 1,\n",
       "             't,': 5,\n",
       "             'ws': 1,\n",
       "             ' N': 1,\n",
       "             'No': 1,\n",
       "             'o,': 2,\n",
       "             'ct': 1,\n",
       "             'uy': 1,\n",
       "             'dr': 1,\n",
       "             'n—': 1,\n",
       "             '— ': 2,\n",
       "             '“J': 1,\n",
       "             'Ju': 1,\n",
       "             't—': 1,\n",
       "             's—': 1,\n",
       "             '—”': 1,\n",
       "             'gn': 3,\n",
       "             'a’': 1,\n",
       "             'sn': 3,\n",
       "             'na': 4,\n",
       "             ' A': 1,\n",
       "             'Al': 1,\n",
       "             'oa': 1,\n",
       "             's)': 1,\n",
       "             'tl': 1,\n",
       "             'g;': 1,\n",
       "             '“W': 1,\n",
       "             'We': 1,\n",
       "             'l,': 1,\n",
       "             'o’': 1,\n",
       "             'tw': 1,\n",
       "             'e?': 1,\n",
       "             '\\nI': 1,\n",
       "             'It': 1,\n",
       "             'ny': 1,\n",
       "             'ep': 2,\n",
       "             'd’': 1,\n",
       "             's’': 1,\n",
       "             '’ ': 1,\n",
       "             '\"W': 1,\n",
       "             'Wh': 1,\n",
       "             'do': 3,\n",
       "             'n?': 1,\n",
       "             'xp': 1,\n",
       "             'gl': 1,\n",
       "             'g.': 1,\n",
       "             'ia': 2,\n",
       "             'f,': 1,\n",
       "             'Le': 2,\n",
       "             '\\nT': 2,\n",
       "             'bb': 1,\n",
       "             'df': 1,\n",
       "             '\"C': 1,\n",
       "             'Cl': 1,\n",
       "             'p!': 1,\n",
       "             '!\"': 1,\n",
       "             'um': 1,\n",
       "             'ls': 1,\n",
       "             'vi': 1})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    " A baseline authorship attribution method \n",
    " based on a character n-gram representation\n",
    " and a linear SVM classifier.\n",
    " It has a reject option to leave documents unattributed\n",
    " (when the probabilities of the two most likely training classes are too close)\n",
    " \n",
    " Questions/comments: stamatatos@aegean.gr\n",
    "\n",
    " It can be applied to datasets of PAN-19 cross-domain authorship attribution task\n",
    " See details here: http://pan.webis.de/clef19/pan19-web/author-identification.html\n",
    " Dependencies:\n",
    " - Python 2.7 or 3.6 (we recommend the Anaconda Python distribution)\n",
    " - scikit-learn\n",
    "\n",
    " Usage from command line: \n",
    "    > python pan19-cdaa-baseline.py -i EVALUATION-DIRECTORY -o OUTPUT-DIRECTORY [-n N-GRAM-ORDER] [-ft FREQUENCY-THRESHOLD] [-pt PROBABILITY-THRESHOLD]\n",
    " EVALUATION-DIRECTORY (str) is the main folder of a PAN-19 collection of attribution problems\n",
    " OUTPUT-DIRECTORY (str) is an existing folder where the predictions are saved in the PAN-19 format\n",
    " Optional parameters of the model:\n",
    "   N-GRAM-ORDER (int) is the length of character n-grams (default=3)\n",
    "   FREQUENCY-THRESHOLD (int) is the cutoff threshold used to filter out rare n-grams (default=5)\n",
    "   PROBABILITY-THRESHOLD (float) is the threshold for the reject option assigning test documents to the <UNK> class (default=0.1)\n",
    "                                 Let P1 and P2 be the two maximum probabilities of training classes for a test document. If P1-P2<pt then the test document is assigned to the <UNK> class.\n",
    "   \n",
    " Example:\n",
    "\n",
    "     >  python pan19-cdaa-baseline-svm.py -i \".\\pan19-cross-domain-authorship-attribution-training-dataset-2019-01-23\\\" -o \".\\a\n",
    "nswers-trigram\\\" -n 3\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "import codecs\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "def represent_text(text,n):\n",
    "    # Extracts all character 'n'-grams from  a 'text'\n",
    "    if n>0:\n",
    "        tokens = [text[i:i+n] for i in range(len(text)-n+1)]\n",
    "    frequency = defaultdict(int)\n",
    "    for token in tokens:\n",
    "        frequency[token] += 1\n",
    "    return frequency\n",
    "\n",
    "represent_text(train_sents[0], 2)\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['g',\n",
       " 'r',\n",
       " 'a',\n",
       " 'c',\n",
       " 'e',\n",
       " 'f',\n",
       " 'u',\n",
       " 'l',\n",
       " ' ',\n",
       " 'o',\n",
       " 'n',\n",
       " 's',\n",
       " '.',\n",
       " '\\n',\n",
       " '\"',\n",
       " 'O',\n",
       " 'm',\n",
       " ',',\n",
       " 'M',\n",
       " 'v',\n",
       " 'i',\n",
       " 'd',\n",
       " 'y',\n",
       " 'b',\n",
       " 'h',\n",
       " 't',\n",
       " 'S',\n",
       " '’',\n",
       " 'J',\n",
       " 'k',\n",
       " '(',\n",
       " 'j',\n",
       " ')',\n",
       " 'H',\n",
       " 'w',\n",
       " ';',\n",
       " 'x',\n",
       " 'p',\n",
       " 'B',\n",
       " '-',\n",
       " 'L',\n",
       " 'T',\n",
       " 'A',\n",
       " 'z',\n",
       " 'Y',\n",
       " '“',\n",
       " '”',\n",
       " 'I',\n",
       " 'Z',\n",
       " '?',\n",
       " '—',\n",
       " 'W',\n",
       " 'C',\n",
       " '!',\n",
       " 'gr',\n",
       " 'ra',\n",
       " 'ac',\n",
       " 'ce',\n",
       " 'ef',\n",
       " 'fu',\n",
       " 'ul',\n",
       " 'l ',\n",
       " ' o',\n",
       " 'on',\n",
       " 'ne',\n",
       " 'es',\n",
       " 's.',\n",
       " '.\\n',\n",
       " '\\n\\n',\n",
       " '\\n\"',\n",
       " 'e ',\n",
       " ' m',\n",
       " 'mo',\n",
       " 'or',\n",
       " 're',\n",
       " 'e,',\n",
       " ',\"',\n",
       " '\" ',\n",
       " ' M',\n",
       " 'Ma',\n",
       " 'ar',\n",
       " 'rv',\n",
       " 've',\n",
       " 'el',\n",
       " 'lo',\n",
       " 'ou',\n",
       " 'us',\n",
       " 's ',\n",
       " ' s',\n",
       " 'sa',\n",
       " 'ai',\n",
       " 'id',\n",
       " 'd,',\n",
       " ', ',\n",
       " 'so',\n",
       " 'un',\n",
       " 'nd',\n",
       " 'di',\n",
       " 'in',\n",
       " 'ng',\n",
       " 'g ',\n",
       " ' r',\n",
       " 'ro',\n",
       " 'oy',\n",
       " 'al',\n",
       " 'll',\n",
       " 'ly',\n",
       " 'y ',\n",
       " ' b',\n",
       " 'bo',\n",
       " 'ed',\n",
       " 'd ',\n",
       " ' f',\n",
       " 'fr',\n",
       " 'om',\n",
       " 'm ',\n",
       " ' h',\n",
       " 'hi',\n",
       " 'is',\n",
       " 'se',\n",
       " 'ea',\n",
       " 'at',\n",
       " 't.',\n",
       " 'Sh',\n",
       " 'he',\n",
       " 'e’',\n",
       " '’s',\n",
       " ' t',\n",
       " 'ti',\n",
       " 'ir',\n",
       " ' J',\n",
       " 'Jo',\n",
       " 'oe',\n",
       " 'th',\n",
       " 'ho',\n",
       " 'ug',\n",
       " 'gh',\n",
       " 'h ',\n",
       " ' n',\n",
       " 'no',\n",
       " 'ot',\n",
       " 't ',\n",
       " ' u',\n",
       " 'nk',\n",
       " 'ki',\n",
       " 'y.',\n",
       " '. ',\n",
       " ' (',\n",
       " '(t',\n",
       " 'uc',\n",
       " 'ck',\n",
       " ' j',\n",
       " 'er',\n",
       " 'rk',\n",
       " '\\nH',\n",
       " 'He',\n",
       " ' w',\n",
       " 'wa',\n",
       " 'as',\n",
       " 'ri',\n",
       " 'ig',\n",
       " 'ht',\n",
       " '; ',\n",
       " 'r ',\n",
       " 'mu',\n",
       " 'sc',\n",
       " 'cl',\n",
       " 'le',\n",
       " 'ha',\n",
       " 'av',\n",
       " ' l',\n",
       " 'si',\n",
       " 'nc',\n",
       " 'tu',\n",
       " 'ur',\n",
       " 'rn',\n",
       " 'to',\n",
       " 'o ',\n",
       " ' c',\n",
       " 'co',\n",
       " 'tt',\n",
       " 'n ',\n",
       " 'wi',\n",
       " 'it',\n",
       " ' e',\n",
       " 'ex',\n",
       " 'au',\n",
       " 'st',\n",
       " 'io',\n",
       " ' a',\n",
       " 'an',\n",
       " ' k',\n",
       " 'kn',\n",
       " 'ee',\n",
       " 'su',\n",
       " 'up',\n",
       " 'pp',\n",
       " 'po',\n",
       " 'rt',\n",
       " 'pr',\n",
       " ' B',\n",
       " 'Bu',\n",
       " 'ut',\n",
       " ' d',\n",
       " 'da',\n",
       " 'am',\n",
       " 'mn',\n",
       " ' i',\n",
       " 'if',\n",
       " 'f ',\n",
       " 'sh',\n",
       " ' g',\n",
       " 'go',\n",
       " 'oi',\n",
       " 'ta',\n",
       " 'ak',\n",
       " 'ke',\n",
       " 'of',\n",
       " 'ff',\n",
       " 'fe',\n",
       " 'p ',\n",
       " 'p,',\n",
       " 'ma',\n",
       " 'rs',\n",
       " 'lf',\n",
       " 'oo',\n",
       " 'ok',\n",
       " 'k ',\n",
       " 'li',\n",
       " 'ik',\n",
       " 'a ',\n",
       " 'we',\n",
       " 'kl',\n",
       " 'nt',\n",
       " 's,',\n",
       " 'wh',\n",
       " ' -',\n",
       " '- ',\n",
       " 'et',\n",
       " 'ca',\n",
       " 'ap',\n",
       " 'pt',\n",
       " 'n.',\n",
       " '\\nL',\n",
       " 'Lu',\n",
       " 'uk',\n",
       " 'ka',\n",
       " 'de',\n",
       " 'te',\n",
       " 'rm',\n",
       " 'mi',\n",
       " ' p',\n",
       " 'ov',\n",
       " 'wo',\n",
       " 'em',\n",
       " 'm,',\n",
       " '\\nS',\n",
       " 'So',\n",
       " 'sl',\n",
       " 'la',\n",
       " 'pe',\n",
       " 'aw',\n",
       " 'ay',\n",
       " 'pu',\n",
       " 'fl',\n",
       " 'r,',\n",
       " 'im',\n",
       " 'me',\n",
       " 'sw',\n",
       " 'rd',\n",
       " 'ec',\n",
       " 'il',\n",
       " 'be',\n",
       " 'tr',\n",
       " 'r.',\n",
       " 'Th',\n",
       " 'hr',\n",
       " ' v',\n",
       " 'vo',\n",
       " 'ic',\n",
       " 'mb',\n",
       " 'bl',\n",
       " 'g,',\n",
       " 'sp',\n",
       " 'sm',\n",
       " ' y',\n",
       " 'wn',\n",
       " 'd.',\n",
       " '\\n(',\n",
       " 'ks',\n",
       " 'm.',\n",
       " '.)',\n",
       " ')\\n',\n",
       " '\\n-',\n",
       " '-\\n',\n",
       " 'ew',\n",
       " 'w ',\n",
       " 'ei',\n",
       " 'ni',\n",
       " ' L',\n",
       " 'iz',\n",
       " 'ju',\n",
       " 'od',\n",
       " 'Yo',\n",
       " 'u ',\n",
       " 'ow',\n",
       " 'ad',\n",
       " 'yo',\n",
       " 'op',\n",
       " 'en',\n",
       " 't’',\n",
       " 'ts',\n",
       " 'ci',\n",
       " 'ip',\n",
       " 'pa',\n",
       " 'xt',\n",
       " 'br',\n",
       " 'mp',\n",
       " 'ie',\n",
       " 'w.',\n",
       " 'dn',\n",
       " 'n’',\n",
       " '’t',\n",
       " 'n,',\n",
       " 'ld',\n",
       " '’d',\n",
       " 'bu',\n",
       " 'ms',\n",
       " 'os',\n",
       " 'lt',\n",
       " 'gu',\n",
       " 'ui',\n",
       " 'ty',\n",
       " 'fo',\n",
       " 'ol',\n",
       " 'ey',\n",
       " 'ye',\n",
       " ' “',\n",
       " 'u’',\n",
       " '’r',\n",
       " 'lk',\n",
       " 'ch',\n",
       " 'h,',\n",
       " ',”',\n",
       " '” ',\n",
       " 'ge',\n",
       " 'oc',\n",
       " 'ba',\n",
       " 'fa',\n",
       " 'ag',\n",
       " 'ga',\n",
       " ' T',\n",
       " 'ss',\n",
       " 'cu',\n",
       " 'ua',\n",
       " 'ru',\n",
       " 'ab',\n",
       " 'e.',\n",
       " ' H',\n",
       " 'pl',\n",
       " 'pi',\n",
       " 'nl',\n",
       " 'rp',\n",
       " 'ns',\n",
       " ') ',\n",
       " '“I',\n",
       " 'I’',\n",
       " '’m',\n",
       " 'eg',\n",
       " 'gi',\n",
       " 'nn',\n",
       " 'y,',\n",
       " 'tc',\n",
       " '.”',\n",
       " '”\\n',\n",
       " 'u.',\n",
       " 'ds',\n",
       " 'gt',\n",
       " 'fi',\n",
       " 'cr',\n",
       " 'ue',\n",
       " 'h.',\n",
       " 'I ',\n",
       " 'Za',\n",
       " 'rc',\n",
       " 'ev',\n",
       " 'ry',\n",
       " ' S',\n",
       " ' I',\n",
       " 'Mi',\n",
       " 'eh',\n",
       " 'yi',\n",
       " 'wr',\n",
       " '’l',\n",
       " 't,',\n",
       " 'ws',\n",
       " 'o,',\n",
       " 'ct',\n",
       " 'dr',\n",
       " '— ',\n",
       " 'gn',\n",
       " 'sn',\n",
       " 'na',\n",
       " ' A',\n",
       " 'tl',\n",
       " 'l,',\n",
       " 'tw',\n",
       " 'It',\n",
       " 'ny',\n",
       " 'ep',\n",
       " 'Wh',\n",
       " 'do',\n",
       " 'xp',\n",
       " 'gl',\n",
       " 'g.',\n",
       " 'ia',\n",
       " 'f,',\n",
       " '\\nT',\n",
       " 'um',\n",
       " 'ls',\n",
       " 'vi',\n",
       " 'gra',\n",
       " 'rac',\n",
       " 'ace',\n",
       " 'efu',\n",
       " 'ful',\n",
       " 'ul ',\n",
       " ' on',\n",
       " 'one',\n",
       " 'nes',\n",
       " 'es.',\n",
       " 's.\\n',\n",
       " '.\\n\\n',\n",
       " '\\n\\n\"',\n",
       " 'ne ',\n",
       " 'e m',\n",
       " ' mo',\n",
       " 'mor',\n",
       " 'ore',\n",
       " 're,',\n",
       " ',\" ',\n",
       " ' Ma',\n",
       " 'Mar',\n",
       " 'arv',\n",
       " 'rve',\n",
       " 'vel',\n",
       " 'elo',\n",
       " 'lou',\n",
       " 'ous',\n",
       " 'us ',\n",
       " 's s',\n",
       " ' sa',\n",
       " 'sai',\n",
       " 'aid',\n",
       " 'id,',\n",
       " 'd, ',\n",
       " ', s',\n",
       " ' so',\n",
       " 'sou',\n",
       " 'oun',\n",
       " 'und',\n",
       " 'ndi',\n",
       " 'din',\n",
       " 'ing',\n",
       " 'ng ',\n",
       " ' ro',\n",
       " 'all',\n",
       " 'lly',\n",
       " 'ly ',\n",
       " 'y b',\n",
       " ' bo',\n",
       " 'red',\n",
       " 'ed ',\n",
       " 'd f',\n",
       " ' fr',\n",
       " 'fro',\n",
       " 'rom',\n",
       " 'om ',\n",
       " 'm h',\n",
       " ' hi',\n",
       " 'his',\n",
       " 'is ',\n",
       " ' se',\n",
       " 'eat',\n",
       " 't.\\n',\n",
       " 'She',\n",
       " 'he’',\n",
       " 'e’s',\n",
       " '’s ',\n",
       " 's t',\n",
       " ' ti',\n",
       " 'ed,',\n",
       " ' Jo',\n",
       " 'Joe',\n",
       " 'oe ',\n",
       " 'e s',\n",
       " ', t',\n",
       " ' th',\n",
       " 'tho',\n",
       " 'hou',\n",
       " 'oug',\n",
       " 'ugh',\n",
       " 'gh ',\n",
       " ' no',\n",
       " 'not',\n",
       " 'ot ',\n",
       " 't u',\n",
       " ' un',\n",
       " 'kin',\n",
       " 'ind',\n",
       " 'ly.',\n",
       " 'y. ',\n",
       " '. (',\n",
       " ' (t',\n",
       " '(th',\n",
       " 'the',\n",
       " 'he ',\n",
       " 'e f',\n",
       " ' fu',\n",
       " 'fuc',\n",
       " 'uck',\n",
       " 'cki',\n",
       " '\\n\\nH',\n",
       " '\\nHe',\n",
       " 'He ',\n",
       " 'e w',\n",
       " ' wa',\n",
       " 'was',\n",
       " 'as ',\n",
       " 's r',\n",
       " ' ri',\n",
       " 'rig',\n",
       " 'igh',\n",
       " 'ght',\n",
       " '; h',\n",
       " ' he',\n",
       " 'her',\n",
       " 'er ',\n",
       " 'r m',\n",
       " ' mu',\n",
       " 'cle',\n",
       " 'les',\n",
       " 'es ',\n",
       " 's h',\n",
       " ' ha',\n",
       " 'hav',\n",
       " 'ave',\n",
       " 've ',\n",
       " 'e l',\n",
       " ' lo',\n",
       " 'lon',\n",
       " 'ong',\n",
       " 'g s',\n",
       " ' si',\n",
       " 'sin',\n",
       " 'inc',\n",
       " 'nce',\n",
       " 'ce ',\n",
       " 'e t',\n",
       " ' tu',\n",
       " 'tur',\n",
       " 'urn',\n",
       " 'rne',\n",
       " 'ned',\n",
       " 'd t',\n",
       " ' to',\n",
       " 'to ',\n",
       " 'o c',\n",
       " ' co',\n",
       " 'ton',\n",
       " 'on ',\n",
       " 'n w',\n",
       " ' wi',\n",
       " 'wit',\n",
       " 'ith',\n",
       " 'th ',\n",
       " ' ex',\n",
       " 'aus',\n",
       " 'ust',\n",
       " 'sti',\n",
       " 'tio',\n",
       " 'ion',\n",
       " 'n a',\n",
       " ' an',\n",
       " 'and',\n",
       " 'nd ',\n",
       " 'd h',\n",
       " ' kn',\n",
       " 'kne',\n",
       " 'nee',\n",
       " ' re',\n",
       " 'ref',\n",
       " 'use',\n",
       " 'sed',\n",
       " 'o s',\n",
       " ' su',\n",
       " 'ppo',\n",
       " 'ort',\n",
       " 'rt ',\n",
       " 't h',\n",
       " ' up',\n",
       " 'pri',\n",
       " 'ht.',\n",
       " 't. ',\n",
       " '. B',\n",
       " ' Bu',\n",
       " 'But',\n",
       " 'ut ',\n",
       " 't d',\n",
       " ' da',\n",
       " 'dam',\n",
       " 'amn',\n",
       " 'd i',\n",
       " ' if',\n",
       " 'if ',\n",
       " 'f s',\n",
       " ' sh',\n",
       " 'she',\n",
       " 's g',\n",
       " ' go',\n",
       " 'goi',\n",
       " 'oin',\n",
       " 'g t',\n",
       " 'o t',\n",
       " ' ta',\n",
       " 'tak',\n",
       " 'ake',\n",
       " 'ke ',\n",
       " 's o',\n",
       " ' of',\n",
       " 'off',\n",
       " 'ffe',\n",
       " 'fer',\n",
       " 'ere',\n",
       " 'han',\n",
       " 'o h',\n",
       " 'p, ',\n",
       " ', a',\n",
       " 'd d',\n",
       " 'o m',\n",
       " ' ma',\n",
       " 'mak',\n",
       " 'e h',\n",
       " 'ers',\n",
       " 'rse',\n",
       " 'sel',\n",
       " 'elf',\n",
       " 'lf ',\n",
       " 'loo',\n",
       " 'ook',\n",
       " 'ok ',\n",
       " ' li',\n",
       " 'lik',\n",
       " 'ike',\n",
       " 'e a',\n",
       " ' a ',\n",
       " 'a w',\n",
       " ' we',\n",
       " 'wea',\n",
       " 'eak',\n",
       " 'lin',\n",
       " 'g i',\n",
       " ' in',\n",
       " 'in ',\n",
       " 'ron',\n",
       " 'nt ',\n",
       " 't o',\n",
       " 'of ',\n",
       " 's, ',\n",
       " ', w',\n",
       " ' wh',\n",
       " 'who',\n",
       " 'ho ',\n",
       " ' - ',\n",
       " '- w',\n",
       " 'whe',\n",
       " 'eth',\n",
       " 'r s',\n",
       " 'ked',\n",
       " ' it',\n",
       " 'it ',\n",
       " ' or',\n",
       " 'or ',\n",
       " 'r n',\n",
       " 't -',\n",
       " 'g c',\n",
       " ' ca',\n",
       " 'tai',\n",
       " 'ain',\n",
       " 'in.',\n",
       " 'n.\\n',\n",
       " '\\n\\nL',\n",
       " 'Luk',\n",
       " 'uka',\n",
       " 'ka ',\n",
       " 's d',\n",
       " ' de',\n",
       " 'ete',\n",
       " 'ter',\n",
       " 'rmi',\n",
       " 'min',\n",
       " 'ine',\n",
       " 'o p',\n",
       " ' pr',\n",
       " 'pro',\n",
       " 'ove',\n",
       " 'r w',\n",
       " ' wo',\n",
       " 'wor',\n",
       " 'rth',\n",
       " 'h t',\n",
       " 'o b',\n",
       " 'bot',\n",
       " 'oth',\n",
       " 'h o',\n",
       " 'f t',\n",
       " 'hem',\n",
       " 'm, ',\n",
       " ', n',\n",
       " 'no ',\n",
       " 'mat',\n",
       " 'att',\n",
       " 'tte',\n",
       " 'wha',\n",
       " 'hat',\n",
       " 'at ',\n",
       " 't i',\n",
       " 't t',\n",
       " 'too',\n",
       " '\\n\\nS',\n",
       " 'So ',\n",
       " ' sl',\n",
       " 'app',\n",
       " 'ppe',\n",
       " 'ped',\n",
       " 'd a',\n",
       " ' aw',\n",
       " 'awa',\n",
       " 'way',\n",
       " 'ay ',\n",
       " 'y a',\n",
       " 'd p',\n",
       " ' pu',\n",
       " 'ush',\n",
       " 'hed',\n",
       " 'oor',\n",
       " 'r, ',\n",
       " 'aim',\n",
       " 'ime',\n",
       " 'med',\n",
       " ' sw',\n",
       " 'ord',\n",
       " 'rd ',\n",
       " ' at',\n",
       " 's n',\n",
       " ' ne',\n",
       " 'wil',\n",
       " 'ill',\n",
       " 'g h',\n",
       " 'r a',\n",
       " ' ar',\n",
       " ' be',\n",
       " 'bet',\n",
       " 'tra',\n",
       " 'y h',\n",
       " 'er.',\n",
       " 'r.\\n',\n",
       " 'ree',\n",
       " ' vo',\n",
       " 'voi',\n",
       " 'oic',\n",
       " 'ice',\n",
       " ' tr',\n",
       " 'tre',\n",
       " 'rem',\n",
       " 'emb',\n",
       " 'bli',\n",
       " 'ng,',\n",
       " 'g, ',\n",
       " 'e r',\n",
       " 'res',\n",
       " 'esp',\n",
       " 'pon',\n",
       " 'ond',\n",
       " 'nde',\n",
       " 'ded',\n",
       " 'd w',\n",
       " 'h a',\n",
       " 'a s',\n",
       " ' sm',\n",
       " 'smi',\n",
       " 's y',\n",
       " 'ed.',\n",
       " 'd.\\n',\n",
       " '\\n\\n(',\n",
       " ', b',\n",
       " '.)\\n',\n",
       " ')\\n\\n',\n",
       " '\\n\\n-',\n",
       " '\\n-\\n',\n",
       " '-\\n\\n',\n",
       " ' fe',\n",
       " 'few',\n",
       " 'ew ',\n",
       " 'w w',\n",
       " 'ks ',\n",
       " 's i',\n",
       " 'int',\n",
       " 'hei',\n",
       " 'eir',\n",
       " 'ir ',\n",
       " 'r t',\n",
       " 'nin',\n",
       " ' Lu',\n",
       " 'rea',\n",
       " 'eal',\n",
       " 'ali',\n",
       " 's j',\n",
       " ' ju',\n",
       " 'jus',\n",
       " 'st ',\n",
       " 'tha',\n",
       " 't g',\n",
       " 'goo',\n",
       " 'ood',\n",
       " 'od ',\n",
       " 'n u',\n",
       " 'You',\n",
       " 'ou ',\n",
       " 'u h',\n",
       " 'o l',\n",
       " ' le',\n",
       " 'lea',\n",
       " 'ear',\n",
       " 'n h',\n",
       " ' ho',\n",
       " 'how',\n",
       " 'ow ',\n",
       " 'w t',\n",
       " 'o r',\n",
       " 'ead',\n",
       " 'ad ',\n",
       " 'd y',\n",
       " ' yo',\n",
       " 'you',\n",
       " 'our',\n",
       " 'ur ',\n",
       " 'r o',\n",
       " ' op',\n",
       " 'opp',\n",
       " 'ent',\n",
       " 't’s',\n",
       " 'ts ',\n",
       " 's a',\n",
       " 'ant',\n",
       " 'nti',\n",
       " 'tic',\n",
       " 'ate',\n",
       " 'te ',\n",
       " 'nex',\n",
       " 'ext',\n",
       " 'xt ',\n",
       " 't m',\n",
       " 're ',\n",
       " 'an ',\n",
       " 'led',\n",
       " 'imp',\n",
       " 'ati',\n",
       " 'ien',\n",
       " 'enc',\n",
       " 'e i',\n",
       " 'e n',\n",
       " 'now',\n",
       " 'ow.',\n",
       " 'may',\n",
       " 'be ',\n",
       " 'it’',\n",
       " 's b',\n",
       " 'bec',\n",
       " 'eca',\n",
       " 'cau',\n",
       " 'se ',\n",
       " 'had',\n",
       " 'dn’',\n",
       " 'n’t',\n",
       " '’t ',\n",
       " 't e',\n",
       " ' ea',\n",
       " 'ten',\n",
       " 'en,',\n",
       " 'n, ',\n",
       " 'id ',\n",
       " 'd s',\n",
       " 'e c',\n",
       " 'cou',\n",
       " 'oul',\n",
       " 'uld',\n",
       " 'ldn',\n",
       " 'unt',\n",
       " 'til',\n",
       " 'il ',\n",
       " 'l s',\n",
       " 'e’d',\n",
       " '’d ',\n",
       " 'd b',\n",
       " 'en ',\n",
       " 't l',\n",
       " 'eas',\n",
       " 'ast',\n",
       " 'onc',\n",
       " 'e, ',\n",
       " ' bu',\n",
       " 'but',\n",
       " 'e k',\n",
       " ' ki',\n",
       " 'o a',\n",
       " ' al',\n",
       " 'low',\n",
       " 'w h',\n",
       " 'him',\n",
       " 'ims',\n",
       " 'mse',\n",
       " 'los',\n",
       " 'ose',\n",
       " 't s',\n",
       " 'so ',\n",
       " 'ld ',\n",
       " 't a',\n",
       " 'elt',\n",
       " 'lt ',\n",
       " ' gu',\n",
       " 'ty ',\n",
       " 'y f',\n",
       " ' fo',\n",
       " 'for',\n",
       " 'r i',\n",
       " 'it.',\n",
       " '\\nSh',\n",
       " 'r e',\n",
       " ' ey',\n",
       " 'eye',\n",
       " 'yes',\n",
       " 'im.',\n",
       " 'm. ',\n",
       " '. “',\n",
       " 'ou’',\n",
       " 'u’r',\n",
       " '’re',\n",
       " 'tal',\n",
       " 'alk',\n",
       " 'oo ',\n",
       " 'h, ',\n",
       " ',” ',\n",
       " 'hen',\n",
       " 'n c',\n",
       " ' ch',\n",
       " 'cha',\n",
       " 'har',\n",
       " 'ged',\n",
       " 'He’',\n",
       " 'd e',\n",
       " 'asi',\n",
       " 'sil',\n",
       " 'ily',\n",
       " ' bl',\n",
       " 'ack',\n",
       " 'ck ',\n",
       " 'k a',\n",
       " 'f h',\n",
       " 'im,',\n",
       " ' ba',\n",
       " 'bar',\n",
       " 'are',\n",
       " 'rel',\n",
       " 'ely',\n",
       " 'fou',\n",
       " 'r f',\n",
       " 'foo',\n",
       " 'oti',\n",
       " 'tin',\n",
       " 'g b',\n",
       " 'bef',\n",
       " 'efo',\n",
       " ' fa',\n",
       " 'fac',\n",
       " ' ag',\n",
       " 'aga',\n",
       " 'gai',\n",
       " 'n. ',\n",
       " '. T',\n",
       " ' Th',\n",
       " 'The',\n",
       " 'sec',\n",
       " 'eco',\n",
       " 'con',\n",
       " 's l',\n",
       " ' la',\n",
       " 'lan',\n",
       " 'g o',\n",
       " ' as',\n",
       " ...]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_files(path,label):\n",
    "    # Reads all text files located in the 'path' and assigns them to 'label' class\n",
    "    files = glob.glob(path+os.sep+label+os.sep+'*.txt')\n",
    "    texts=[]\n",
    "    for i,v in enumerate(files):\n",
    "        f=codecs.open(v,'r',encoding='utf-8')\n",
    "        texts.append((f.read(),label))\n",
    "        f.close()\n",
    "    return texts\n",
    "\n",
    "def extract_vocabulary(texts,n,ft):\n",
    "    # Extracts all characer 'n'-grams occurring at least 'ft' times in a set of 'texts'\n",
    "    occurrences=defaultdict(int) \n",
    "    for (text,label) in texts:\n",
    "        text_occurrences = {}\n",
    "        if isinstance(n, int):\n",
    "            for x in range(1,n+1):\n",
    "                text_occurrences.update(represent_text(text,x))\n",
    "        else:\n",
    "            pass\n",
    "        for ngram in text_occurrences:\n",
    "            if ngram in occurrences:\n",
    "                occurrences[ngram]+=text_occurrences[ngram]\n",
    "            else:\n",
    "                occurrences[ngram]=text_occurrences[ngram]\n",
    "    vocabulary=[]\n",
    "    for i in occurrences.keys():\n",
    "        if occurrences[i]>=ft:\n",
    "            vocabulary.append(i)\n",
    "    return vocabulary\n",
    "\n",
    "extract_vocabulary([(x,i) for i, x in enumerate(train_sents)], 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem00001\n",
      "(140, 64239)\n",
      "\t language:  en\n",
      "\t 20 candidate authors\n",
      "\t 140 known texts\n",
      "\t vocabulary size: 64239\n",
      "\t 105 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sallyisa/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/sallyisa/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/sallyisa/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/sallyisa/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 30 texts left unattributed\n",
      "\t answers saved to file answers-problem00001.json\n",
      "problem00002\n",
      "(35, 26761)\n",
      "\t language:  en\n",
      "\t 5 candidate authors\n",
      "\t 35 known texts\n",
      "\t vocabulary size: 26761\n",
      "\t 21 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sallyisa/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/sallyisa/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/sallyisa/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/sallyisa/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 7 texts left unattributed\n",
      "\t answers saved to file answers-problem00002.json\n",
      "elapsed time: 32.0657012462616\n"
     ]
    }
   ],
   "source": [
    "def baseline(path,outpath,n=3,ft=5,pt=0.1):\n",
    "    start_time = time.time()\n",
    "    # Reading information about the collection\n",
    "    infocollection = path+os.sep+'collection-info.json'\n",
    "    problems = []\n",
    "    language = []\n",
    "    with open(infocollection, 'r') as f:\n",
    "        for attrib in json.load(f):\n",
    "            problems.append(attrib['problem-name'])\n",
    "            language.append(attrib['language'])\n",
    "    for index,problem in enumerate(problems):\n",
    "        print(problem)\n",
    "        # Reading information about the problem\n",
    "        infoproblem = path+os.sep+problem+os.sep+'problem-info.json'\n",
    "        candidates = []\n",
    "        with open(infoproblem, 'r') as f:\n",
    "            fj = json.load(f)\n",
    "            unk_folder = fj['unknown-folder']\n",
    "            for attrib in fj['candidate-authors']:\n",
    "                candidates.append(attrib['author-name'])\n",
    "        # Building training set\n",
    "        train_docs=[]\n",
    "        for candidate in candidates:\n",
    "            train_docs.extend(read_files(path+os.sep+problem,candidate))\n",
    "        train_texts = [text for i,(text,label) in enumerate(train_docs)]\n",
    "        train_labels = [label for i,(text,label) in enumerate(train_docs)]\n",
    "        vocabulary = extract_vocabulary(train_docs,n,ft)\n",
    "        vectorizer = CountVectorizer(analyzer='char',ngram_range=(n,n),lowercase=False,vocabulary=vocabulary)\n",
    "        train_data = vectorizer.fit_transform(train_texts)\n",
    "        train_data = train_data.astype(float)\n",
    "        print(train_data.shape)\n",
    "        for i,v in enumerate(train_texts):\n",
    "            train_data[i]=train_data[i]/len(train_texts[i]) # normalizes over length?\n",
    "        print('\\t', 'language: ', language[index])\n",
    "        print('\\t', len(candidates), 'candidate authors')\n",
    "        print('\\t', len(train_texts), 'known texts')\n",
    "        print('\\t', 'vocabulary size:', len(vocabulary))\n",
    "        # Building test set\n",
    "        test_docs=read_files(path+os.sep+problem,unk_folder)\n",
    "        test_texts = [text for i,(text,label) in enumerate(test_docs)]\n",
    "        test_data = vectorizer.transform(test_texts)\n",
    "        test_data = test_data.astype(float)\n",
    "        for i,v in enumerate(test_texts):\n",
    "            test_data[i]=test_data[i]/len(test_texts[i])\n",
    "        print('\\t', len(test_texts), 'unknown texts')\n",
    "        # Applying SVM\n",
    "        max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "        scaled_train_data = max_abs_scaler.fit_transform(train_data)\n",
    "        scaled_test_data = max_abs_scaler.transform(test_data)\n",
    "        clf=CalibratedClassifierCV(OneVsRestClassifier(SVC(C=1)))\n",
    "        clf.fit(scaled_train_data, train_labels)\n",
    "        predictions=clf.predict(scaled_test_data)\n",
    "        proba=clf.predict_proba(scaled_test_data)\n",
    "        # Reject option (used in open-set cases)\n",
    "        count=0\n",
    "        for i,p in enumerate(predictions):\n",
    "            sproba=sorted(proba[i],reverse=True)\n",
    "            if sproba[0]-sproba[1]<pt:\n",
    "                predictions[i]=u'<UNK>'\n",
    "                count=count+1\n",
    "        print('\\t',count,'texts left unattributed')\n",
    "        # Saving output data\n",
    "        out_data=[]\n",
    "        unk_filelist = glob.glob(path+os.sep+problem+os.sep+unk_folder+os.sep+'*.txt')\n",
    "        pathlen=len(path+os.sep+problem+os.sep+unk_folder+os.sep)\n",
    "        for i,v in enumerate(predictions):\n",
    "            out_data.append({'unknown-text': unk_filelist[i][pathlen:], 'predicted-author': v})\n",
    "        with open(outpath+os.sep+'answers-'+problem+'.json', 'w') as f:\n",
    "            json.dump(out_data, f, indent=4)\n",
    "        print('\\t', 'answers saved to file','answers-'+problem+'.json')\n",
    "    print('elapsed time:', time.time() - start_time)\n",
    "\n",
    "base_dir='pan18-cross-domain-authorship-attribution-training-dataset-2017-12-02'\n",
    "out_dir = base_dir+os.sep+'output-dir'\n",
    "eval_dir = base_dir+os.sep+'eval-dir'\n",
    "baseline(base_dir,out_dir,n=5,ft=3,pt=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem00001 Macro-F1: 0.559\n",
      "problem00002 Macro-F1: 0.633\n",
      "Overall score: 0.596\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "# Evaluation script for the Cross-Domain Authorship Attribution task @PAN2019.\n",
    "We use the F1 metric (macro-average) as implemented in scikit-learn:\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "We include the following ad hoc rules:\n",
    "- If authors are predicted which were not seen during training,\n",
    "  these predictions will count as false predictions ('<UNK>' class)\n",
    "  and they will negatively effect performance.\n",
    "- If texts are left unattributed they will assigned to the ('<UNK>'\n",
    "  class) and they will negatively effect performance.\n",
    "- The <UNK> class is excluded from the macro-average across classes.\n",
    "- If multiple test attributions are given for a single unknown document,\n",
    "  only the first one will be taken into consideration.\n",
    "\n",
    "Dependencies:\n",
    "- Python 2.7 or 3.6 (we recommend the Anaconda Python distribution)\n",
    "- scikit-learn\n",
    "\n",
    "Usage from the command line:\n",
    ">>> python pan19-cdaa-evaluator.py -i COLLECTION -a ANSWERS -o OUTPUT\n",
    "where\n",
    "    COLLECTION is the path to the main folder of the evaluation collection\n",
    "    ANSWERS is the path to the answers folder of a submitted method\n",
    "    OUTPUT is the path to the folder where the results of the evaluation will be saved\n",
    "\n",
    "Example: \n",
    ">>>  python pan19-cdaa-evaluator.py -i \".\\pan19-cross-domain-authorship-attribution-training-dataset-2019-01-23\\\" -a \".\\answ\n",
    "ers-unigram\" -o \".\\eval-unigram\\\"\n",
    "\n",
    "# References:\n",
    "@article{scikit-learn,\n",
    " title={Scikit-learn: Machine Learning in {P}ython},\n",
    " author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n",
    "         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n",
    "         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n",
    "         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n",
    " journal={Journal of Machine Learning Research},\n",
    " volume={12},\n",
    " pages={2825--2830},\n",
    " year={2011}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "def eval_measures(gt, pred):\n",
    "    \"\"\"Compute macro-averaged F1-scores, macro-averaged precision, \n",
    "    macro-averaged recall, and micro-averaged accuracy according the ad hoc\n",
    "    rules discussed at the top of this file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    gt : dict\n",
    "        Ground truth, where keys indicate text file names\n",
    "        (e.g. `unknown00002.txt`), and values represent\n",
    "        author labels (e.g. `candidate00003`)\n",
    "    pred : dict\n",
    "        Predicted attribution, where keys indicate text file names\n",
    "        (e.g. `unknown00002.txt`), and values represent\n",
    "        author labels (e.g. `candidate00003`)\n",
    "    Returns\n",
    "    -------\n",
    "    f1 : float\n",
    "        Macro-averaged F1-score\n",
    "    precision : float\n",
    "        Macro-averaged precision\n",
    "    recall : float\n",
    "        Macro-averaged recall\n",
    "    accuracy : float\n",
    "        Micro-averaged F1-score\n",
    "    \"\"\"\n",
    "\n",
    "    actual_authors = list(gt.values())\n",
    "    encoder = LabelEncoder().fit(['<UNK>'] + actual_authors)\n",
    "\n",
    "    text_ids, gold_authors, silver_authors = [], [], []\n",
    "    for text_id in sorted(gt):\n",
    "        text_ids.append(text_id)\n",
    "        gold_authors.append(gt[text_id])\n",
    "        try:\n",
    "            silver_authors.append(pred[text_id])\n",
    "        except KeyError:\n",
    "            # missing attributions get <UNK>:\n",
    "            silver_authors.append('<UNK>')\n",
    "\n",
    "    assert len(text_ids) == len(gold_authors)\n",
    "    assert len(text_ids) == len(silver_authors)\n",
    "\n",
    "    # replace non-existent silver authors with '<UNK>':\n",
    "    silver_authors = [a if a in encoder.classes_ else '<UNK>' \n",
    "                      for a in silver_authors]\n",
    "\n",
    "    gold_author_ints = encoder.transform(gold_authors)\n",
    "    silver_author_ints = encoder.transform(silver_authors)\n",
    "\n",
    "    # get F1 for individual classes (and suppress warnings):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        labels=list(set(gold_author_ints))\n",
    "        # Exclude the <UNK> class\n",
    "        for x in labels:\n",
    "            if encoder.inverse_transform(np.array([x]))=='<UNK>':\n",
    "                labels.remove(x)\n",
    "        f1 = f1_score(gold_author_ints,\n",
    "                  silver_author_ints,\n",
    "                  labels,\n",
    "                  average='macro')\n",
    "        precision = precision_score(gold_author_ints,\n",
    "                  silver_author_ints,\n",
    "                  labels,\n",
    "                  average='macro')\n",
    "        recall = recall_score(gold_author_ints,\n",
    "                  silver_author_ints,\n",
    "                  labels,\n",
    "                  average='macro')\n",
    "        accuracy = accuracy_score(gold_author_ints,\n",
    "                  silver_author_ints)\n",
    "\n",
    "    return f1,precision,recall\n",
    "\n",
    "def evaluate(ground_truth_file,predictions_file):\n",
    "    # Calculates evaluation measures for a single attribution problem\n",
    "    gt = {}\n",
    "    with open(ground_truth_file, 'r') as f:\n",
    "        for attrib in json.load(f)['ground_truth']:\n",
    "            gt[attrib['unknown-text']] = attrib['true-author']\n",
    "\n",
    "    pred = {}\n",
    "    with open(predictions_file, 'r') as f:\n",
    "        for attrib in json.load(f):\n",
    "            if attrib['unknown-text'] not in pred:\n",
    "                pred[attrib['unknown-text']] = attrib['predicted-author']\n",
    "    f1,precision,recall =  eval_measures(gt,pred)\n",
    "    return round(f1,3), round(precision,3), round(recall,3)\n",
    "\n",
    "def evaluate_all(path_collection,path_answers,path_out):\n",
    "    # Calculates evaluation measures for a PAN-18 collection of attribution problems\n",
    "    infocollection = path_collection+os.sep+'collection-info.json'\n",
    "    problems = []\n",
    "    data = []\n",
    "    with open(infocollection, 'r') as f:\n",
    "        for attrib in json.load(f):\n",
    "            problems.append(attrib['problem-name'])\n",
    "    scores=[];\n",
    "    for problem in problems:\n",
    "        f1,precision,recall=evaluate(path_collection+os.sep+problem+os.sep+'ground-truth.json',path_answers+os.sep+'answers-'+problem+'.json')\n",
    "        scores.append(f1)\n",
    "        data.append({'problem-name': problem, 'macro-f1': round(f1,3), 'macro-precision': round(precision,3), 'macro-recall': round(recall,3)})\n",
    "        print(str(problem),'Macro-F1:',round(f1,3))\n",
    "    overall_score=sum(scores)/len(scores)\n",
    "    # Saving data to output files (out.json and evaluation.prototext)\n",
    "    with open(path_out+os.sep+'out.json', 'w') as f:\n",
    "        json.dump({'problems': data, 'overall_score': round(overall_score,3)}, f, indent=4, sort_keys=True)\n",
    "    print('Overall score:', round(overall_score,3))\n",
    "    prototext='measure {\\n key: \"mean macro-f1\"\\n value: \"'+str(round(overall_score,3))+'\"\\n}\\n'\n",
    "    with open(path_out+os.sep+'evaluation.prototext', 'w') as f:\n",
    "        f.write(prototext)\n",
    "   \n",
    "evaluate_all(base_dir,out_dir,eval_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dir_files(path):\n",
    "    dir_files = []\n",
    "    for file in os.listdir(path):\n",
    "        current = os.path.join(path, file)\n",
    "        if os.path.isfile(current):\n",
    "            dir_files.append(open_file(current))\n",
    "    return dir_files\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['graceful ones.\\n\\n\"One more,\" Marvelous said, sounding royally bored from his seat.\\n\\n\"She’s tired,\" Joe said, though not unkindly. (the fucking jerk).\\n\\nHe was right; her muscles have long since turned to cotton with exhaustion and her knees refused to support her upright. But damned if she was going to take Joe’s offered hand to help her up, and damned if she was going to make herself look like a weakling in front of Marvelous, who - whether she liked it or not - was the fucking captain.\\n\\nLuka was determined to prove her worth to both of them, no matter what it took.\\n\\nSo she slapped Joe’s hand away and pushed herself off the fucking floor, and aimed the sword at his neck, willing her arm not to betray her.\\n\\n\"Three more,\" she said, voice trembling, and Joe responded with a smirk.\\n\\nMarvelous yawned.\\n\\n(fucking jerks, both of them.)\\n\\n-\\n\\nA few weeks into their training, and Luka realized Joe was just that good in using his sword.\\n\\n\"You have to learn how to read your opponent’s thoughts and anticipate their next move,\" Joe said, and there was an unbridled impatience in his tone now.\\n\\n(maybe it’s because she hadn’t eaten, because Marvelous said she couldn’t eat until she’d beaten Joe at least once, but Joe was not the kind to allow himself to lose just so she could fucking eat and felt guilty for it.)\\n\\nShe rolled her eyes at him. “You’re talking too much, Joe,” Luka said, then charged at him.\\n\\nHe’d easily blocked her attack and pushed her off of him, and she’d barely found her footing before he was at her face again. The next second she was landing on her ass, looking up at Joe and cursing him in all the languages she knew.\\n\\nMarvelous grunted and made his way to the dining table. He uncovered a plate of boiled meat (the smell made her mouth water despite the distance because her eyes weren’t the only sharp sense she had, fucking damnit) and looked at her. “I’m beginning to wonder if you’re going to eat some time today, Luka, or if you’re just going to stand there and watch us when we dine.”\\n\\n(fuck you.)\\n\\nJoe’s jaw tightened, and he said, “You’re being too harsh, Marvelous. Luka needs her strength if she’s to fight me.”\\n\\nShe couldn’t tell if he was showing her kindness or cruelty or both.\\n\\n(fuck you.)\\n\\n\"I have to be,\" Marvelous said, and for the first time there was an edge to his voice. \"The Zangyack forces are getting stronger every day. She’s as good to me dead if she can’t fight for her life. If she can’t fight for me.\" He shrugged. \"Might as well leave her behind in our next stop.\"\\n\\nLuka gritted her teeth. “Are you saying I’m weak?”\\n\\n\"Are you?\"\\n\\n\"You’re wrong and I’ll prove it,\" Luka said, the claws of desperation beginning to run up her veins. No, no, the prospect of attaining the greatest treasure, of her buying a planet for children— “Just— Marvelous—”\\n\\nMarvelous yawned again, and positioned himself to ignore her and eat.\\n\\nLuka’s temper snapped. All she wanted was to slit their throats as wide as she could (their fault for putting a sword in her hands) but then she settled with saying; “Well, if I’m not going to eat - who’s to say the two of you are?”\\n\\nIt’s a wonder she was even able to speak evenly when there was a gnawing pain in her stomach and it was agony just to keep her fingers around the sword’s handle. But it was worth it, when Marvelous’ head snapped up to look at her, and Joe began to regard her with growing suspicion.\\n\\n\"What do you mean?\"\\n\\nShe placed a hand on her hip and grinned cockily. “I like to experiment every once in a while in the kitchen, when I’m alone,” she said, lying through her teeth because she never had a kitchen to step foot in before, and she wasn’t about to start now. “I may have placed something in the food that shouldn’t be there in the first place.”\\n\\nMarvelous glanced at the plate and crossed his arms. “You’re lying.”\\n\\nShe made herself look appropriately outraged. “I’m a thief, not a liar. Learn the difference.”\\n\\nTheir captain gnashed his teeth. “I don’t believe you.” He grabbed a handful of the meat, brought it up to his face. He opened his mouth, thought better of it, and smelled the food instead.\\n\\nThe next moment, he was throwing it at his feet.\\n\\n\"Clean that up!\" he barked, turning his back on her and stalking towards the door - presumably to eat somewhere else.\\n\\nLeaving',\n",
       " 'before. If he can, he’ll remember a classmate from his old school (you’ll never catch me!), his homeroom teacher (thank you for bringing me flowers today), even an older girl who later becomes his brother’s sort-of-girlfriend (no she’s not, get back to your drawings.) He’d had tons of crushes, so this isn’t new.\\n\\n2. What is new is the intensity in his chest and the giddiness engulfing him whenever she’s near. What’s new is the sudden helplessness he feels about these feelings, too.\\n\\n3. Whenever she’s within his line of sight, he’ll start to feel the telltale signs; an itch at the back of his tongue that makes him incessantly clear his throat, the urge to tug and straighten his shirt and tie to seem more presentable, more pleasing, somehow. His glasses are always askew and needs constant adjusting, too.\\n\\n4. When she speaks to him… oh, boy. Often he’s reduced to an even more incoherent, blubbering mess and he hates it - but it’s not like he can help it, either.\\n\\n5. Mio doesn’t seem to mind, though. She only tilts her head and looks at him quizzically - Tokatti, are you alright? - and of course he’ll say he is, of course, don’t be silly, of course he’s fine, no, really! Of course!\\n\\nShe’ll quietly hand him a handkerchief and he won’t know why until later when he realizes that he’s been sweating buckets all along. Sigh.\\n\\n6. It isn’t like he woke up one day and decided that he likes Mio, he thinks. It gradually builds up - every kindness, every smile, every compassionate act forming an unfathomable, unbreakable thing that wraps around his heart and refuses to let go. He’s spent some nights tossing and turning because contrary to what he thinks, he’s smart enough to know and understand exactly what it is that he’s feeling.\\n\\n7. Not that knowing and understanding it made things easier, though. The question is - what is he going to do about it?\\n\\n8. Out of desperation, he once asked Right about it - without being too specific, of course. That day Right’s eyes shone so brightly; he nodded and said, with ramen stuck in his teeth, I understand how you feel! That’s exactly how I am when I think about my favorite bento and barbecue together…!\\n\\nThat’s when he decides that, nope, Right doesn’t understand and nope, Right doesn’t need to know more.\\n\\n9. Another time he asked Kagura about it and fifteen minutes later, the two of them were reenacting a scene from Cinderella and no, he really doesn’t remember how they jumped from point A to point B, exactly, just that suddenly he’s putting on glass slippers and they were dancing and Kagura was giggling and so was he.\\n\\nIt had been a lovely day.\\n\\n10. Of course he’s thought about asking Hikari, but decides against the idea quickly. After all, Hikari’s the most perceptive of them all and he may start asking perceptive  questions and make deductive conclusions and no, he’s not yet prepared for that.\\n\\nAnd then circumstances forces Hikari to know about his crush and, well, Tokatti’s got to admit, it’s sort of nice to have someone else know his secret.\\n\\n11. No, he hasn’t asked Akira. He isn’t going to. The last conversation they had together, they were talking about bread crumbs and somehow that lead to a dramatic declaration of bakeries being among the greatest places to die in (closing your eyes with baked bread being the very last thing you see…! I can only hope that my death will be as peaceful!)  and really, he didn’t know how that happened. He bet Akira didn’t, either.\\n\\n12. So he’s sort of stuck at this weird place where he knows he likes someone but isn’t too keen on acting on it - because he doesn’t know how. He’ll just be here, bidding his time while trying not to feel too jealousenvious when Mio hounds Right because of his antics, or when she tries to cook and feed Hikari all his favorite (and not so favorite) foods, or when she grabs Kagura’s hand each time the group has to split up.\\n\\n13. For now, he’ll happily soak up each smile she gives him and try his best to appreciate every little thing she does for the group - even look out for her in battle, just in case. Not that she needs it; she’s a better fighter than he can ever aspire to be. But still.\\n\\n14. For now, he’ll happily ignore the fact that she has yet to fuss over him the way she usually does for Right, Hikari, and Kagura.\\n\\n15. After all,',\n",
       " 'she thought - he was in Team Baron only because, for some reason, he was able to stay in Kaito Kumon’s good graces. It was better to be unmemorable and forgotten than to be remembered only through sheer underhandedness and rotten deeds, she’d tell him - if he asked.\\n\\n(He didn’t.)\\n3. They rarely spoke, rarely acknowledged each other, rarely referred to the other specifically. Gaim’s and Baron’s worlds were intertwined, but his and hers, blissfully, were not.\\n4. Then the world they thought they knew was thrown askew, and nothing was ever the same again.\\n5. His first solo encounter with her was quite awkward, truth be told. There was an intense discussion going on in the garage, and opinions were being voiced out and shot down and he had no idea what to do but he knew he needed to relieve himself, and so he stepped backwards and disappeared from the group and no one noticed. He was about to barge into the bathroom when he thought he heard soft, mewling sounds; he was about to open his mouth when the door swung suddenly and he stood face-to-face with her, that Gaim-girl-who-wasn’t-Mai.\\n6. Her eyes were wet and red. Hastily, she wiped at her cheeks and moved away from him, and the sight brought a peculiar weight on his gut.\\n7. Later she’d tell him she was crying because others simply weren’t. They all sounded so sure and so confident about what to do when the world was ending and— well, what if they failed? What if they died? They were only human, and young. Some of them were beltless, too. What could they do?\\n8. He’d point out that Mai was also beltless, and she’d smile at him and say well, she wasn’t Mai, who had not an iota of powerlessness and fear within her. She’d add that he wasn’t Kaito Kumon, either; he had not the power or the strength to fight. Really, in their group, the two of them were basically cannon fodder, because their names so happened to be Chucky and Peko, not Mai and Kaito.\\n9. He didn’t have anything to say to her after that, because he knew her words to be true. He thought, maybe if he was given a belt like Zack was, then things would change - but he didn’t get one, and so nothing did. She stared at him and wiped at her eyes again, before bidding him goodnight.\\n10. When it was his and Mai’s turn to go shopping, he remembered to pick up everything Zack and Kaito told him to. Zack didn’t tell him to buy a handkerchief, though - and yet, he did.\\n11. The next thing he knew, his body had turned into a cornucopia of aches and bloody joints that even breathing became an exercise of sheer will. When he opened his eyes, it was to the sight of her tending to his wounds. Her eyes were misty, but she wasn’t crying, and her hands were soft as she tended to him. He was grateful for it.\\n12. One day, out of nowhere, she thanked him. Then, laughing and embarrassed, she said that his injuries gave her an excuse to be busy, to have something else to focus on - he basically became her reason to live, and she was grateful for it. It was an odd and quite insensitive thing to say, but his jaw hurts and so he was only able to mumble his indignation. She smiled.\\n13. It was eerily quiet when it was just the two of them in the garage, because, due to some reason or the other, the Gaim and Baron members stopped coming to them. Most days were all right; but during nighttime, when the littlest scrapes could mean their impending doom, sleeping could almost be considered a luxury - one that he often gave to her. He’d smile at her and say it’s her prize for taking care of him, then clutch his slingshot, and keep an eye out for both their sakes. Oftentimes he’d wish for his own driver - but one never came.\\n14. When news of Mai’s death came to them, she took it the hardest. It was their fault, she said, for trusting Micchy, for being stupid and foolish and stupid. Tears ran freely down her cheeks, and there was a peculiar weight in his gut and stinging in his eyes as he stood to get something he’d bought for her earlier. She stared at the handkerchief he offered as though it was an alien concept. He smiled and told her to take it.\\n15. Later, when the world was being remade, they’d learn of Kaito’s fate and he’d be the one who would take the news hard. He’d question why it happened and how a person like Kaito would fall that far; why',\n",
       " \"As far as she remembers, she's always hated princesses and their vanity and fondness for frilly pinks and their ever-present need to be saved from harm time and again.  they're catalysts. their capture motivates the heroes to move.  they're idiots. why can't they ever rescue themselves?  then what good are their heroes for?  -  She runs and runs and runs while her friends all die behind her, all die for her - to save her, give her a chance to escape.  She can hear them, the sounds they made, can imagine the last breath they took, the last thought they had:  save us.  She's princess and hero in one, but she isn't aware of anything else other than the burning in her legs and the ugly taste of fear coating her tongue.  -  The first few days after the first time it happened, something's irrevocably changed in the dynamics of their group.  She's gone from 'tolerable' to 'indispensable', and suddenly her welfare is all they are concerned about.  has she eaten?  is she feeling well?   she needs to rest. i'll watch over her.  She's always the first to be fed, the first to be offered a chance to sleep, the first whose wounds are tended to, and she hates it, hates the hungry eyes watching her every bite, the tired bodies guarding her as she counts the stars every night.  But she knows she has her role to play, just like they do, if they all want to live.  She takes comfort in the thought that they're forced to do this, care for her this way, not because she's like some goddamned damsel in distress but because if she dies, they all do. Her survival must be ensured so theirs can be, too. They're saving her now, so she can save them when the time is right.  Closing her eyes, she wonders for how long they can keep doing this. If living is even worth the sacrifices they're forced to make everyday. If getting caught and ripped to pieces is the easier choice to make.  Dying is never pretty, but who says surviving isn't?  -  He holds her hands and she sighs, leaning on him, needing the contact despite the coldness of his skin.  it's been seven times now.  how'd you know?  i asked.  She shivers. She knows, having asked the question, herself.  (and sometimes, sometimes, if she concentrates hard enough - she can glimpse the fragments of gruesome truth that bishop never tells them about - unless they asked.)  He was the third to die, that day-that-never-was. Just after James, but before Clarice. Peter was the first, Roberto, last.  The order sometimes varies, but all the line-ups always have one thing in common:  She's never in it.  i'm sorry.  what for?  -  She runs and runs and her eyes meet his as his ice takes him to his doom.  no! no!  Her heart constricts and sobs threaten to explode in her chest but she can't stop, won't stop, not even to say goodbye to him because if she does, if she wastes a goddamned second, then his death will have meant nothing.  So she lets him go, lets him die, lets him be the sentinel's plaything in her stead - all to buy her time to reset things.  To give them another chance to relive this awful cycle again, and again, and again...  \\xa0-  (she lies awake beside him that night, listens to clarice and james talk like old friends, listens to bishop and peter bond like family, listens to roberto snore up a storm.  and it's times like this one that makes her realize that survival may be fucking hard but it's worth it - if only because she still gets to enjoy moments like this, with them.)\",\n",
       " '“Wait for me, please!”\\n\\nShe glanced towards the owner of the voice and internally cursed. Quickly, she pressed the ‘close’ button several times - and kept herself from grinning when the elevator doors closed before his idiotic face.\\n\\nA small victory for her, she thought, after he’d trounced her so completely in the courtroom that morning.\\n\\n-\\n\\nLooking at her opponent now, she couldn’t believe she’d once considered him a bumbling fool.\\n\\nHe made his closing statement so convincingly that a small sliver of her soul was moved - even as her mind pushed the sentiment away.\\n\\nShe pursed her lips and glanced at the judges. Already, she could sense that they were being swayed towards her enemy’s side.\\n\\nBreathing through her closed mouth, she wondered when it was, exactly, that she’d become so ineffective in her job.\\n\\n-\\n\\nThe next time she encountered him, he was wearing those glasses of his that inexplicably drove her to the wall.\\n\\nThey were so ill-fitting, she thought, that a part of her wanted to rip them off his face and crush them underneath her heel as he watched in horror.\\n\\n(he was more handsome without that pesky thing, anyway.)\\n\\nOf course, she did neither of those things.\\n\\n(nor did she entertain the thought that he was handsome.)\\n\\nShe did nod at him courteously when he greeted her with her trademark idiotic grin - and that was that.\\n\\n-\\n\\n“Ah, Prosecutor Seo - I wanted to consult with you on something.”\\n\\nShe affixed on him her most withering glare - the one that sent most of her staff scurrying away - and said, “Attorney Cha. I believe my assistant has informed you of my unavailability–”\\n\\n“I won’t take much of your time,” he insisted, pushing her door open and depositing himself within her orbit. “There’s just this little angle we haven’t thought of–”\\n\\nShe gritted her teeth and kept herself from trying to strangle him for his impudence. She was, after all, a prosecutor - not a law-offender.\\n\\nTen minutes later, and found herself agreeing with him on several points, and reaffirming just why he was a formidable opponent, when he tried.\\n\\n-\\n\\n“Ah - hold the elevator, please.”\\n\\nShe was fumbling through her bag, intent on locating her phone, that she didn’t even look at who was in the elevator before she stepped in.\\n\\nIt was him.\\n\\nOf course it was.\\n\\nPoliteness dictated that she tell him, “Thank you,” and she did.\\n\\nHe smiled. “It’s nothing,” he said.\\n\\nShe glanced at the side and silently counted - ten more floors. Thank goodness it was a short ride.\\n\\n“Great work today,” he said, trying to start a conversation.\\n\\nFrom any other person, she would have taken that as some sort of veiled insult. Coming from him, though, it was– it felt– genuine. That, in itself, baffled her. So she straightened her spine and said,\\xa0\"Of course. Your defense was weak to begin with.“ Of course I’d win.\\n\\nThe victory felt hollow, but it was still a victory.\\n\\nHe chuckled and said, \"It was. I’ve had many sleepless nights trying to find some way to win the case - but of course, like they say, you can’t win them all.”\\n\\nThe elevator doors reflected him clearly, and from there she could see the dark circles under his eyes.\\n\\nHe’s not wearing glasses, she thought belatedly.\\n\\n“It’s a saying we all abide by,” she said blithely.\\n\\nShe almost bit her tongue afterwards. What an inane response.\\n\\nThe elevator doors opened, and as she stepped through them he said, “Have a good day!” He even did a little wave and grinned at her, before disappearing altogether.\\n\\nShe drew a deep breath.\\n\\nIdiot.',\n",
       " 'Zawame City’s no longer ‘home’ as it once was. You know this as gospel truth, ever since Yggdrasil robbed everything from you. Yet it hasn’t been this empty, this cold before, and you shiver, despite your resolve to not let it swallow you whole. - So many people have already left. Slipped out when and while they can. You think they’re smart people, then; they know they can’t fight what’s coming, that they’re too weak to face the unknown. Their strength is in knowing that they’re not strong. In a way, you respect them for it, even if in the scheme of things they’re at the very bottom of the food chain - easily crushed. Easily destroyed. There’s only so few of you left to fight for a vacant city. In a way, you anticipate what’s coming. You welcome it - the chance to show your power. Your strength. Even if there aren’t anyone around to witness it. Power is power -\\xa0and you know what you have now is not enough, but it’ll do. It’ll have to do - or you’ll die showing them your worth. You have no intention of giving up, despite your limited power, even if there’s only so few of you left. (this is your true strength.) - Some of your (temporary) allies are not strong. You know this. You know they know this, just as you all know everyone has a role to play in this war - even the weak ones, who can serve as distraction until the stronger ones can come to their aid. You look around the room (so few of you left) and you gauge their strength - or lack of it. You wonder why she stayed behind, but you don’t ask. (You know why, though.) You’re fiercely glad she hasn’t left. -what’s wrong? You ask her, because her silence isn’t something you welcome in your head. You don’t want to admit it, but her words are an odd sort of relieving distraction, from all the fighting you do. And she replies with words you thought of, before - this city’s no longer home, now that everyone’s gone; it’s just a ruin - and you abhor just how pathetic and small she sounds, just then.where’s your hope? You want to ask, but don’t. Instead, you tell her to change her way of looking at the now - consider it as a sort of freedom. You wonder why you even bother to comfort her. Especially when she utters the words you hate the most: I’m not that strong.(You told her that, yourself. Once.) And you call out her name, and tell her to dance, because that’s where her strength lies. And you spin your tale, telling her that there’s hope people will come back to the city because she has some ability to gather people around her, and you know it’s the truth, because you’ve seen it for yourself. How she’s managed to unite the different teams to perform as one group, something you’re sure hasn’t been done before. Something you’re sure isn’t possible, before. (before her.) Still, you wonder why you don’t disregard her sorrow, when this is not a time to indulge in such weakness. But you hear the smile in her voice (finally), and you think it’s time well worth wasting. Still, she surprises you, by casually, cheerfully throwing your words at your face: isn’t that you, Kaito? All of a sudden, Team Gaim, Team Baron, even Yggdrasil are fighting together - because of you. You think it’s an absurd notion, but you swallow all the words.That’s why— That’s why— The sound of an opening crack has never been more welcomed. (over and out.)',\n",
       " \"1. He showered her with smiles the first time he saw her; after all,\\xa0he was never one to think anything so ungraciously about a woman - any woman, for that matter - nor was he the type to be so unwelcoming to guests, no matter what their status in life was.\\n\\n2. The way he lathered on lotion on that woman's back made her cringe; his hands were so big and purposeful and his expression was so slick and knowing and no, she did not just entertain the thought of those hands wandering down her own back - no, no, thank you!\\n\\n3. She was smart enough to know that his smile was the kind of smile meant to make any woman's knees buckle, just as he was smart enough to know it wouldn't buckle hers, no matter how wide or charming he made it to be (not that he tried that hard, though).\\n\\n4. For some reason he found it verrrrry interesting to watch his best friend act around her; he couldn't explain why, just that he had a gut feeling it was like watching a train wreck in progress - but in a good, kinda comical way.\\n\\n5. (That last one didn't make a lot of sense, but then his friend's actions didn't make a lot of sense either, so.)\\n\\n6. She only knew him on a surface level, though if she was to rate the four boys her best friend was suddenly involved with in terms of who she was most familiar and/or comfortable with, then he'd come a really close second.\\n\\n7. The first time they got the opportunity to really talk, it was not at all forced or awkward; there was a fluidity to their conversation that he found refreshing and she, surprising.\\n\\n8. From that first time, it was only natural that their 'friendship' grew to a level where they could exchange smiles with an easily graspable sincerity, as well as ask about how the other was and actually be interested in the reply.\\n\\n9. When he heard about what he did to her at the restaurant, he was surprised that he actually had to think about what to do first - go to him, or go to her - in the end, though, there really was no contest about what he should do in a situation like this.\\n\\n(he went to him first.)\\n\\n10. A part of her associated him with his best friend - so when she was angry and hurt and heartbroken, in some insane, unexplainable moments she was angry and hurt and heartbroken because of two people, not just one.\\n\\n11. But she appreciated that he never sought her out to explain his friend's actions - some things were just unexplainable, after all.\\n\\n12. He didn't know how, exactly, but somehow they were able to right all wrongs and the next time he saw her, he himself was surprised at how happy she seemed to be, though there was a tinge of sadness in her expression, too, and when they talked, he was finally able to know why that was.\\n\\n13. They were left behind, just the two of them, and she found him to be a source of welcomed comfort every now and then - his schedule didn't permit them to meet too often, but when they do, he could always make her smile and laugh like no one else could, and secretly she wondered what if she fell for him instead and--\\n\\n14. He'd be lying if he said he didn't think about pursuing her the way he did women he found interesting, appealing, and enchanting - but she was Ga Eul and he was Woo Bin and no matter how he looked at it, the two of them would always have Yi Jung between them.\\n\\n15. Besides, he rarely had relationships that lasted this long, and he found out that he vastly preferred to live with her in his life than without.\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def open_file(path):\n",
    "    with open(path, 'r+') as f:\n",
    "        return '\\n'.join([line.strip() for line in f])\n",
    "\n",
    "\n",
    "train_sents= process_dir_files('pan18-cross-domain-authorship-attribution-training-dataset-2017-12-02/problem00001/candidate00001')\n",
    "train_sents\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['graceful ones.\\n\\n\"One more,\" Marvelous said, sounding royally bored from his seat.\\n\\n\"She’s tired,\" Joe said, though not unkindly. (the fucking jerk).\\n\\nHe was right; her muscles have long since turned to cotton with exhaustion and her knees refused to support her upright. But damned if she was going to take Joe’s offered hand to help her up, and damned if she was going to make herself look like a weakling in front of Marvelous, who - whether she liked it or not - was the fucking captain.\\n\\nLuka was determined to prove her worth to both of them, no matter what it took.\\n\\nSo she slapped Joe’s hand away and pushed herself off the fucking floor, and aimed the sword at his neck, willing her arm not to betray her.\\n\\n\"Three more,\" she said, voice trembling, and Joe responded with a smirk.\\n\\nMarvelous yawned.\\n\\n(fucking jerks, both of them.)\\n\\n-\\n\\nA few weeks into their training, and Luka realized Joe was just that good in using his sword.\\n\\n\"You have to learn how to read your opponent’s thoughts and anticipate their next move,\" Joe said, and there was an unbridled impatience in his tone now.\\n\\n(maybe it’s because she hadn’t eaten, because Marvelous said she couldn’t eat until she’d beaten Joe at least once, but Joe was not the kind to allow himself to lose just so she could fucking eat and felt guilty for it.)\\n\\nShe rolled her eyes at him. “You’re talking too much, Joe,” Luka said, then charged at him.\\n\\nHe’d easily blocked her attack and pushed her off of him, and she’d barely found her footing before he was at her face again. The next second she was landing on her ass, looking up at Joe and cursing him in all the languages she knew.\\n\\nMarvelous grunted and made his way to the dining table. He uncovered a plate of boiled meat (the smell made her mouth water despite the distance because her eyes weren’t the only sharp sense she had, fucking damnit) and looked at her. “I’m beginning to wonder if you’re going to eat some time today, Luka, or if you’re just going to stand there and watch us when we dine.”\\n\\n(fuck you.)\\n\\nJoe’s jaw tightened, and he said, “You’re being too harsh, Marvelous. Luka needs her strength if she’s to fight me.”\\n\\nShe couldn’t tell if he was showing her kindness or cruelty or both.\\n\\n(fuck you.)\\n\\n\"I have to be,\" Marvelous said, and for the first time there was an edge to his voice. \"The Zangyack forces are getting stronger every day. She’s as good to me dead if she can’t fight for her life. If she can’t fight for me.\" He shrugged. \"Might as well leave her behind in our next stop.\"\\n\\nLuka gritted her teeth. “Are you saying I’m weak?”\\n\\n\"Are you?\"\\n\\n\"You’re wrong and I’ll prove it,\" Luka said, the claws of desperation beginning to run up her veins. No, no, the prospect of attaining the greatest treasure, of her buying a planet for children— “Just— Marvelous—”\\n\\nMarvelous yawned again, and positioned himself to ignore her and eat.\\n\\nLuka’s temper snapped. All she wanted was to slit their throats as wide as she could (their fault for putting a sword in her hands) but then she settled with saying; “Well, if I’m not going to eat - who’s to say the two of you are?”\\n\\nIt’s a wonder she was even able to speak evenly when there was a gnawing pain in her stomach and it was agony just to keep her fingers around the sword’s handle. But it was worth it, when Marvelous’ head snapped up to look at her, and Joe began to regard her with growing suspicion.\\n\\n\"What do you mean?\"\\n\\nShe placed a hand on her hip and grinned cockily. “I like to experiment every once in a while in the kitchen, when I’m alone,” she said, lying through her teeth because she never had a kitchen to step foot in before, and she wasn’t about to start now. “I may have placed something in the food that shouldn’t be there in the first place.”\\n\\nMarvelous glanced at the plate and crossed his arms. “You’re lying.”\\n\\nShe made herself look appropriately outraged. “I’m a thief, not a liar. Learn the difference.”\\n\\nTheir captain gnashed his teeth. “I don’t believe you.” He grabbed a handful of the meat, brought it up to his face. He opened his mouth, thought better of it, and smelled the food instead.\\n\\nThe next moment, he was throwing it at his feet.\\n\\n\"Clean that up!\" he barked, turning his back on her and stalking towards the door - presumably to eat somewhere else.\\n\\nLeaving',\n",
       " 'before. If he can, he’ll remember a classmate from his old school (you’ll never catch me!), his homeroom teacher (thank you for bringing me flowers today), even an older girl who later becomes his brother’s sort-of-girlfriend (no she’s not, get back to your drawings.) He’d had tons of crushes, so this isn’t new.\\n\\n2. What is new is the intensity in his chest and the giddiness engulfing him whenever she’s near. What’s new is the sudden helplessness he feels about these feelings, too.\\n\\n3. Whenever she’s within his line of sight, he’ll start to feel the telltale signs; an itch at the back of his tongue that makes him incessantly clear his throat, the urge to tug and straighten his shirt and tie to seem more presentable, more pleasing, somehow. His glasses are always askew and needs constant adjusting, too.\\n\\n4. When she speaks to him… oh, boy. Often he’s reduced to an even more incoherent, blubbering mess and he hates it - but it’s not like he can help it, either.\\n\\n5. Mio doesn’t seem to mind, though. She only tilts her head and looks at him quizzically - Tokatti, are you alright? - and of course he’ll say he is, of course, don’t be silly, of course he’s fine, no, really! Of course!\\n\\nShe’ll quietly hand him a handkerchief and he won’t know why until later when he realizes that he’s been sweating buckets all along. Sigh.\\n\\n6. It isn’t like he woke up one day and decided that he likes Mio, he thinks. It gradually builds up - every kindness, every smile, every compassionate act forming an unfathomable, unbreakable thing that wraps around his heart and refuses to let go. He’s spent some nights tossing and turning because contrary to what he thinks, he’s smart enough to know and understand exactly what it is that he’s feeling.\\n\\n7. Not that knowing and understanding it made things easier, though. The question is - what is he going to do about it?\\n\\n8. Out of desperation, he once asked Right about it - without being too specific, of course. That day Right’s eyes shone so brightly; he nodded and said, with ramen stuck in his teeth, I understand how you feel! That’s exactly how I am when I think about my favorite bento and barbecue together…!\\n\\nThat’s when he decides that, nope, Right doesn’t understand and nope, Right doesn’t need to know more.\\n\\n9. Another time he asked Kagura about it and fifteen minutes later, the two of them were reenacting a scene from Cinderella and no, he really doesn’t remember how they jumped from point A to point B, exactly, just that suddenly he’s putting on glass slippers and they were dancing and Kagura was giggling and so was he.\\n\\nIt had been a lovely day.\\n\\n10. Of course he’s thought about asking Hikari, but decides against the idea quickly. After all, Hikari’s the most perceptive of them all and he may start asking perceptive  questions and make deductive conclusions and no, he’s not yet prepared for that.\\n\\nAnd then circumstances forces Hikari to know about his crush and, well, Tokatti’s got to admit, it’s sort of nice to have someone else know his secret.\\n\\n11. No, he hasn’t asked Akira. He isn’t going to. The last conversation they had together, they were talking about bread crumbs and somehow that lead to a dramatic declaration of bakeries being among the greatest places to die in (closing your eyes with baked bread being the very last thing you see…! I can only hope that my death will be as peaceful!)  and really, he didn’t know how that happened. He bet Akira didn’t, either.\\n\\n12. So he’s sort of stuck at this weird place where he knows he likes someone but isn’t too keen on acting on it - because he doesn’t know how. He’ll just be here, bidding his time while trying not to feel too jealousenvious when Mio hounds Right because of his antics, or when she tries to cook and feed Hikari all his favorite (and not so favorite) foods, or when she grabs Kagura’s hand each time the group has to split up.\\n\\n13. For now, he’ll happily soak up each smile she gives him and try his best to appreciate every little thing she does for the group - even look out for her in battle, just in case. Not that she needs it; she’s a better fighter than he can ever aspire to be. But still.\\n\\n14. For now, he’ll happily ignore the fact that she has yet to fuss over him the way she usually does for Right, Hikari, and Kagura.\\n\\n15. After all,',\n",
       " 'she thought - he was in Team Baron only because, for some reason, he was able to stay in Kaito Kumon’s good graces. It was better to be unmemorable and forgotten than to be remembered only through sheer underhandedness and rotten deeds, she’d tell him - if he asked.\\n\\n(He didn’t.)\\n3. They rarely spoke, rarely acknowledged each other, rarely referred to the other specifically. Gaim’s and Baron’s worlds were intertwined, but his and hers, blissfully, were not.\\n4. Then the world they thought they knew was thrown askew, and nothing was ever the same again.\\n5. His first solo encounter with her was quite awkward, truth be told. There was an intense discussion going on in the garage, and opinions were being voiced out and shot down and he had no idea what to do but he knew he needed to relieve himself, and so he stepped backwards and disappeared from the group and no one noticed. He was about to barge into the bathroom when he thought he heard soft, mewling sounds; he was about to open his mouth when the door swung suddenly and he stood face-to-face with her, that Gaim-girl-who-wasn’t-Mai.\\n6. Her eyes were wet and red. Hastily, she wiped at her cheeks and moved away from him, and the sight brought a peculiar weight on his gut.\\n7. Later she’d tell him she was crying because others simply weren’t. They all sounded so sure and so confident about what to do when the world was ending and— well, what if they failed? What if they died? They were only human, and young. Some of them were beltless, too. What could they do?\\n8. He’d point out that Mai was also beltless, and she’d smile at him and say well, she wasn’t Mai, who had not an iota of powerlessness and fear within her. She’d add that he wasn’t Kaito Kumon, either; he had not the power or the strength to fight. Really, in their group, the two of them were basically cannon fodder, because their names so happened to be Chucky and Peko, not Mai and Kaito.\\n9. He didn’t have anything to say to her after that, because he knew her words to be true. He thought, maybe if he was given a belt like Zack was, then things would change - but he didn’t get one, and so nothing did. She stared at him and wiped at her eyes again, before bidding him goodnight.\\n10. When it was his and Mai’s turn to go shopping, he remembered to pick up everything Zack and Kaito told him to. Zack didn’t tell him to buy a handkerchief, though - and yet, he did.\\n11. The next thing he knew, his body had turned into a cornucopia of aches and bloody joints that even breathing became an exercise of sheer will. When he opened his eyes, it was to the sight of her tending to his wounds. Her eyes were misty, but she wasn’t crying, and her hands were soft as she tended to him. He was grateful for it.\\n12. One day, out of nowhere, she thanked him. Then, laughing and embarrassed, she said that his injuries gave her an excuse to be busy, to have something else to focus on - he basically became her reason to live, and she was grateful for it. It was an odd and quite insensitive thing to say, but his jaw hurts and so he was only able to mumble his indignation. She smiled.\\n13. It was eerily quiet when it was just the two of them in the garage, because, due to some reason or the other, the Gaim and Baron members stopped coming to them. Most days were all right; but during nighttime, when the littlest scrapes could mean their impending doom, sleeping could almost be considered a luxury - one that he often gave to her. He’d smile at her and say it’s her prize for taking care of him, then clutch his slingshot, and keep an eye out for both their sakes. Oftentimes he’d wish for his own driver - but one never came.\\n14. When news of Mai’s death came to them, she took it the hardest. It was their fault, she said, for trusting Micchy, for being stupid and foolish and stupid. Tears ran freely down her cheeks, and there was a peculiar weight in his gut and stinging in his eyes as he stood to get something he’d bought for her earlier. She stared at the handkerchief he offered as though it was an alien concept. He smiled and told her to take it.\\n15. Later, when the world was being remade, they’d learn of Kaito’s fate and he’d be the one who would take the news hard. He’d question why it happened and how a person like Kaito would fall that far; why',\n",
       " \"As far as she remembers, she's always hated princesses and their vanity and fondness for frilly pinks and their ever-present need to be saved from harm time and again.  they're catalysts. their capture motivates the heroes to move.  they're idiots. why can't they ever rescue themselves?  then what good are their heroes for?  -  She runs and runs and runs while her friends all die behind her, all die for her - to save her, give her a chance to escape.  She can hear them, the sounds they made, can imagine the last breath they took, the last thought they had:  save us.  She's princess and hero in one, but she isn't aware of anything else other than the burning in her legs and the ugly taste of fear coating her tongue.  -  The first few days after the first time it happened, something's irrevocably changed in the dynamics of their group.  She's gone from 'tolerable' to 'indispensable', and suddenly her welfare is all they are concerned about.  has she eaten?  is she feeling well?   she needs to rest. i'll watch over her.  She's always the first to be fed, the first to be offered a chance to sleep, the first whose wounds are tended to, and she hates it, hates the hungry eyes watching her every bite, the tired bodies guarding her as she counts the stars every night.  But she knows she has her role to play, just like they do, if they all want to live.  She takes comfort in the thought that they're forced to do this, care for her this way, not because she's like some goddamned damsel in distress but because if she dies, they all do. Her survival must be ensured so theirs can be, too. They're saving her now, so she can save them when the time is right.  Closing her eyes, she wonders for how long they can keep doing this. If living is even worth the sacrifices they're forced to make everyday. If getting caught and ripped to pieces is the easier choice to make.  Dying is never pretty, but who says surviving isn't?  -  He holds her hands and she sighs, leaning on him, needing the contact despite the coldness of his skin.  it's been seven times now.  how'd you know?  i asked.  She shivers. She knows, having asked the question, herself.  (and sometimes, sometimes, if she concentrates hard enough - she can glimpse the fragments of gruesome truth that bishop never tells them about - unless they asked.)  He was the third to die, that day-that-never-was. Just after James, but before Clarice. Peter was the first, Roberto, last.  The order sometimes varies, but all the line-ups always have one thing in common:  She's never in it.  i'm sorry.  what for?  -  She runs and runs and her eyes meet his as his ice takes him to his doom.  no! no!  Her heart constricts and sobs threaten to explode in her chest but she can't stop, won't stop, not even to say goodbye to him because if she does, if she wastes a goddamned second, then his death will have meant nothing.  So she lets him go, lets him die, lets him be the sentinel's plaything in her stead - all to buy her time to reset things.  To give them another chance to relive this awful cycle again, and again, and again...  \\xa0-  (she lies awake beside him that night, listens to clarice and james talk like old friends, listens to bishop and peter bond like family, listens to roberto snore up a storm.  and it's times like this one that makes her realize that survival may be fucking hard but it's worth it - if only because she still gets to enjoy moments like this, with them.)\",\n",
       " '“Wait for me, please!”\\n\\nShe glanced towards the owner of the voice and internally cursed. Quickly, she pressed the ‘close’ button several times - and kept herself from grinning when the elevator doors closed before his idiotic face.\\n\\nA small victory for her, she thought, after he’d trounced her so completely in the courtroom that morning.\\n\\n-\\n\\nLooking at her opponent now, she couldn’t believe she’d once considered him a bumbling fool.\\n\\nHe made his closing statement so convincingly that a small sliver of her soul was moved - even as her mind pushed the sentiment away.\\n\\nShe pursed her lips and glanced at the judges. Already, she could sense that they were being swayed towards her enemy’s side.\\n\\nBreathing through her closed mouth, she wondered when it was, exactly, that she’d become so ineffective in her job.\\n\\n-\\n\\nThe next time she encountered him, he was wearing those glasses of his that inexplicably drove her to the wall.\\n\\nThey were so ill-fitting, she thought, that a part of her wanted to rip them off his face and crush them underneath her heel as he watched in horror.\\n\\n(he was more handsome without that pesky thing, anyway.)\\n\\nOf course, she did neither of those things.\\n\\n(nor did she entertain the thought that he was handsome.)\\n\\nShe did nod at him courteously when he greeted her with her trademark idiotic grin - and that was that.\\n\\n-\\n\\n“Ah, Prosecutor Seo - I wanted to consult with you on something.”\\n\\nShe affixed on him her most withering glare - the one that sent most of her staff scurrying away - and said, “Attorney Cha. I believe my assistant has informed you of my unavailability–”\\n\\n“I won’t take much of your time,” he insisted, pushing her door open and depositing himself within her orbit. “There’s just this little angle we haven’t thought of–”\\n\\nShe gritted her teeth and kept herself from trying to strangle him for his impudence. She was, after all, a prosecutor - not a law-offender.\\n\\nTen minutes later, and found herself agreeing with him on several points, and reaffirming just why he was a formidable opponent, when he tried.\\n\\n-\\n\\n“Ah - hold the elevator, please.”\\n\\nShe was fumbling through her bag, intent on locating her phone, that she didn’t even look at who was in the elevator before she stepped in.\\n\\nIt was him.\\n\\nOf course it was.\\n\\nPoliteness dictated that she tell him, “Thank you,” and she did.\\n\\nHe smiled. “It’s nothing,” he said.\\n\\nShe glanced at the side and silently counted - ten more floors. Thank goodness it was a short ride.\\n\\n“Great work today,” he said, trying to start a conversation.\\n\\nFrom any other person, she would have taken that as some sort of veiled insult. Coming from him, though, it was– it felt– genuine. That, in itself, baffled her. So she straightened her spine and said,\\xa0\"Of course. Your defense was weak to begin with.“ Of course I’d win.\\n\\nThe victory felt hollow, but it was still a victory.\\n\\nHe chuckled and said, \"It was. I’ve had many sleepless nights trying to find some way to win the case - but of course, like they say, you can’t win them all.”\\n\\nThe elevator doors reflected him clearly, and from there she could see the dark circles under his eyes.\\n\\nHe’s not wearing glasses, she thought belatedly.\\n\\n“It’s a saying we all abide by,” she said blithely.\\n\\nShe almost bit her tongue afterwards. What an inane response.\\n\\nThe elevator doors opened, and as she stepped through them he said, “Have a good day!” He even did a little wave and grinned at her, before disappearing altogether.\\n\\nShe drew a deep breath.\\n\\nIdiot.',\n",
       " 'Zawame City’s no longer ‘home’ as it once was. You know this as gospel truth, ever since Yggdrasil robbed everything from you. Yet it hasn’t been this empty, this cold before, and you shiver, despite your resolve to not let it swallow you whole. - So many people have already left. Slipped out when and while they can. You think they’re smart people, then; they know they can’t fight what’s coming, that they’re too weak to face the unknown. Their strength is in knowing that they’re not strong. In a way, you respect them for it, even if in the scheme of things they’re at the very bottom of the food chain - easily crushed. Easily destroyed. There’s only so few of you left to fight for a vacant city. In a way, you anticipate what’s coming. You welcome it - the chance to show your power. Your strength. Even if there aren’t anyone around to witness it. Power is power -\\xa0and you know what you have now is not enough, but it’ll do. It’ll have to do - or you’ll die showing them your worth. You have no intention of giving up, despite your limited power, even if there’s only so few of you left. (this is your true strength.) - Some of your (temporary) allies are not strong. You know this. You know they know this, just as you all know everyone has a role to play in this war - even the weak ones, who can serve as distraction until the stronger ones can come to their aid. You look around the room (so few of you left) and you gauge their strength - or lack of it. You wonder why she stayed behind, but you don’t ask. (You know why, though.) You’re fiercely glad she hasn’t left. -what’s wrong? You ask her, because her silence isn’t something you welcome in your head. You don’t want to admit it, but her words are an odd sort of relieving distraction, from all the fighting you do. And she replies with words you thought of, before - this city’s no longer home, now that everyone’s gone; it’s just a ruin - and you abhor just how pathetic and small she sounds, just then.where’s your hope? You want to ask, but don’t. Instead, you tell her to change her way of looking at the now - consider it as a sort of freedom. You wonder why you even bother to comfort her. Especially when she utters the words you hate the most: I’m not that strong.(You told her that, yourself. Once.) And you call out her name, and tell her to dance, because that’s where her strength lies. And you spin your tale, telling her that there’s hope people will come back to the city because she has some ability to gather people around her, and you know it’s the truth, because you’ve seen it for yourself. How she’s managed to unite the different teams to perform as one group, something you’re sure hasn’t been done before. Something you’re sure isn’t possible, before. (before her.) Still, you wonder why you don’t disregard her sorrow, when this is not a time to indulge in such weakness. But you hear the smile in her voice (finally), and you think it’s time well worth wasting. Still, she surprises you, by casually, cheerfully throwing your words at your face: isn’t that you, Kaito? All of a sudden, Team Gaim, Team Baron, even Yggdrasil are fighting together - because of you. You think it’s an absurd notion, but you swallow all the words.That’s why— That’s why— The sound of an opening crack has never been more welcomed. (over and out.)',\n",
       " \"1. He showered her with smiles the first time he saw her; after all,\\xa0he was never one to think anything so ungraciously about a woman - any woman, for that matter - nor was he the type to be so unwelcoming to guests, no matter what their status in life was.\\n\\n2. The way he lathered on lotion on that woman's back made her cringe; his hands were so big and purposeful and his expression was so slick and knowing and no, she did not just entertain the thought of those hands wandering down her own back - no, no, thank you!\\n\\n3. She was smart enough to know that his smile was the kind of smile meant to make any woman's knees buckle, just as he was smart enough to know it wouldn't buckle hers, no matter how wide or charming he made it to be (not that he tried that hard, though).\\n\\n4. For some reason he found it verrrrry interesting to watch his best friend act around her; he couldn't explain why, just that he had a gut feeling it was like watching a train wreck in progress - but in a good, kinda comical way.\\n\\n5. (That last one didn't make a lot of sense, but then his friend's actions didn't make a lot of sense either, so.)\\n\\n6. She only knew him on a surface level, though if she was to rate the four boys her best friend was suddenly involved with in terms of who she was most familiar and/or comfortable with, then he'd come a really close second.\\n\\n7. The first time they got the opportunity to really talk, it was not at all forced or awkward; there was a fluidity to their conversation that he found refreshing and she, surprising.\\n\\n8. From that first time, it was only natural that their 'friendship' grew to a level where they could exchange smiles with an easily graspable sincerity, as well as ask about how the other was and actually be interested in the reply.\\n\\n9. When he heard about what he did to her at the restaurant, he was surprised that he actually had to think about what to do first - go to him, or go to her - in the end, though, there really was no contest about what he should do in a situation like this.\\n\\n(he went to him first.)\\n\\n10. A part of her associated him with his best friend - so when she was angry and hurt and heartbroken, in some insane, unexplainable moments she was angry and hurt and heartbroken because of two people, not just one.\\n\\n11. But she appreciated that he never sought her out to explain his friend's actions - some things were just unexplainable, after all.\\n\\n12. He didn't know how, exactly, but somehow they were able to right all wrongs and the next time he saw her, he himself was surprised at how happy she seemed to be, though there was a tinge of sadness in her expression, too, and when they talked, he was finally able to know why that was.\\n\\n13. They were left behind, just the two of them, and she found him to be a source of welcomed comfort every now and then - his schedule didn't permit them to meet too often, but when they do, he could always make her smile and laugh like no one else could, and secretly she wondered what if she fell for him instead and--\\n\\n14. He'd be lying if he said he didn't think about pursuing her the way he did women he found interesting, appealing, and enchanting - but she was Ga Eul and he was Woo Bin and no matter how he looked at it, the two of them would always have Yi Jung between them.\\n\\n15. Besides, he rarely had relationships that lasted this long, and he found out that he vastly preferred to live with her in his life than without.\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Combine all features for each sentence.\n",
    "\n",
    "Combine all the previous features, and generate a matrix encoding all previously mentioned features: unigrams, bigrams, trigrams and pos_tags. The resulting matrix should have the following dimensions: 3x31\n",
    "\n",
    "You could use the `sklearn.pipeline.FeatureUnion` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#toks = sentence_tokenize(train_sentences)\n",
    "\n",
    "pipe2 = Pipeline (FeatureUnion([(\"uni\", CountVectorizer(ngram_range = (1,3), min_df = 1)),(\"PoS\", nltk.word_tokenize(train_sentences_1[0]))])\n",
    "\n",
    "\n",
    "#CountVectorizer(ngram_range = (1,1), min_df = 1) #token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\"\n",
    "\n",
    "#bigrams_bow = bigr.fit_transform(train_sentences)\n",
    "#union.fit_transform(train_sentences)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra to play with: Check this website and think about it. Do you think you can use this for something? (in the exam)\n",
    "\n",
    "http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHARE YOUR KNOWLEDGE!\n",
    "\n",
    "### Do you know any other way of representing the features of the training/testing set?\n",
    "\n",
    "Please share your knowledge using the forum from Absalon!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
