{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "\n",
    "In this notebook we will learn how to extract different features from a text and how to combine them. It's pretty simple, but if you have this part well organized, it will be really useful in the near future. So, let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "import codecs\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import random\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(path):\n",
    "    with open(path, 'r+', encoding='utf8') as f:\n",
    "        return '\\n'.join([line.strip() for line in f])\n",
    "    \n",
    "def process_dir_files(path):\n",
    "    dir_files = []\n",
    "    for file in os.listdir(path):\n",
    "        current = os.path.join(path, file)\n",
    "        if os.path.isfile(current):\n",
    "            dir_files.append(open_file(current))\n",
    "    return dir_files\n",
    "                     \n",
    "\n",
    "#train_sents= process_dir_files('pan18-cross-domain-authorship-attribution-training-dataset-2017-12-02/problem00001/candidate00001')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def get_pos(text):\n",
    "    pos_tags= nltk.pos_tag(word_tokenize(text))\n",
    "    # print(len(pos_tags))\n",
    "    pos_tags = [word_tag[1] for word_tag in pos_tags]\n",
    "    pos_text = ' '.join(pos_tags)\n",
    "    return pos_tags\n",
    "\n",
    "#get_pos(train_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_ngrams(sents):\n",
    "    pos_tags= [nltk.pos_tag(word_tokenize(sents[ind])) for ind, item in enumerate(sents) if item != '']\n",
    "    pos_sents = []\n",
    "    for sent in pos_tags:\n",
    "        #print(sent)\n",
    "        pos = ' '.join([pos_tag[1] for pos_tag in sent])\n",
    "        #print(pos, '\\n')\n",
    "        pos_sents.append(pos)\n",
    "    vectorizer = CountVectorizer(ngram_range = (1,1))\n",
    "    vectorizer.fit(pos_sents)\n",
    "    return vectorizer\n",
    "\n",
    "\n",
    "#pos_vectorizer = get_pos_ngrams(train_sents)\n",
    "#pos_ngram = pos_vectorizer.transform(train_sents)\n",
    "#pos_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    " A baseline authorship attribution method \n",
    " based on a character n-gram representation\n",
    " and a linear SVM classifier.\n",
    " It has a reject option to leave documents unattributed\n",
    " (when the probabilities of the two most likely training classes are too close)\n",
    " \n",
    " Questions/comments: stamatatos@aegean.gr\n",
    "\n",
    " It can be applied to datasets of PAN-19 cross-domain authorship attribution task\n",
    " See details here: http://pan.webis.de/clef19/pan19-web/author-identification.html\n",
    " Dependencies:\n",
    " - Python 2.7 or 3.6 (we recommend the Anaconda Python distribution)\n",
    " - scikit-learn\n",
    "\n",
    " Usage from command line: \n",
    "    > python pan19-cdaa-baseline.py -i EVALUATION-DIRECTORY -o OUTPUT-DIRECTORY [-n N-GRAM-ORDER] [-ft FREQUENCY-THRESHOLD] [-pt PROBABILITY-THRESHOLD]\n",
    " EVALUATION-DIRECTORY (str) is the main folder of a PAN-19 collection of attribution problems\n",
    " OUTPUT-DIRECTORY (str) is an existing folder where the predictions are saved in the PAN-19 format\n",
    " Optional parameters of the model:\n",
    "   N-GRAM-ORDER (int) is the length of character n-grams (default=3)\n",
    "   FREQUENCY-THRESHOLD (int) is the cutoff threshold used to filter out rare n-grams (default=5)\n",
    "   PROBABILITY-THRESHOLD (float) is the threshold for the reject option assigning test documents to the <UNK> class (default=0.1)\n",
    "                                 Let P1 and P2 be the two maximum probabilities of training classes for a test document. If P1-P2<pt then the test document is assigned to the <UNK> class.\n",
    "   \n",
    " Example:\n",
    "\n",
    "     >  python pan19-cdaa-baseline-svm.py -i \".\\pan19-cross-domain-authorship-attribution-training-dataset-2019-01-23\\\" -o \".\\a\n",
    "nswers-trigram\\\" -n 3\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "import codecs\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "def represent_text(text,n,pos=False):\n",
    "    # Extracts all character n-grams from  a 'text'\n",
    "    # if pos is True, extracts POS n-grams\n",
    "    if n>0:\n",
    "        if pos is True:\n",
    "            text = get_pos(text)\n",
    "            tokens = [' '.join(text[i:i+n]) for i in range(len(text)-n+1)]\n",
    "            #print(tokens)\n",
    "        else:\n",
    "            tokens = [text[i:i+n] for i in range(len(text)-n+1)]\n",
    "    frequency = defaultdict(int)\n",
    "    for token in tokens:\n",
    "        frequency[token] += 1\n",
    "    return frequency\n",
    "\n",
    "#represent_text(train_sents[0], 2)\n",
    "#represent_text(train_sents[0], 2, pos=True)\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nvocab = extract_vocabulary([(x,i) for i, x in enumerate(train_sents)], 2, 5, pos=True)\\nprint(len(vocab))\\nprint(vocab)\\nvectorizer = CountVectorizer(vocabulary=[x.lower() for  x in vocab])\\nprint([' '.join(get_pos(text)) for text in train_sents])\\n\\ntrain_data = vectorizer.fit_transform([' '.join(get_pos(text)) for text in train_sents])\\nprint(vectorizer.get_feature_names())\\ntrain_data = train_data.astype(float)\\nprint(train_data.shape)\\nprint(train_data.toarray())\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_files(path,label):\n",
    "    # Reads all text files located in the 'path' and assigns them to 'label' class\n",
    "    files = glob.glob(path+os.sep+label+os.sep+'*.txt')\n",
    "    texts=[]\n",
    "    for i,v in enumerate(files):\n",
    "        f=codecs.open(v,'r',encoding='utf-8')\n",
    "        texts.append((f.read(),label))\n",
    "        f.close()\n",
    "    return texts\n",
    "\n",
    "def extract_vocabulary(texts,n,ft,pos=False):\n",
    "    # Extracts all characer 'n'-grams occurring at least 'ft' times in a set of 'texts'\n",
    "    occurrences=defaultdict(int) \n",
    "    for (text,label) in texts:\n",
    "        text_occurrences = {}\n",
    "        if isinstance(n, int):\n",
    "            for x in range(1,n+1):\n",
    "                text_occurrences.update(represent_text(text,x,pos=pos))\n",
    "        else:\n",
    "            pass\n",
    "        for ngram in text_occurrences:\n",
    "            if ngram in occurrences:\n",
    "                occurrences[ngram]+=text_occurrences[ngram]\n",
    "            else:\n",
    "                occurrences[ngram]=text_occurrences[ngram]\n",
    "    vocabulary=[]\n",
    "    for i in occurrences.keys():\n",
    "        if occurrences[i]>=ft:\n",
    "            vocabulary.append(i)\n",
    "    return vocabulary\n",
    "\n",
    "'''\n",
    "vocab = extract_vocabulary([(x,i) for i, x in enumerate(train_sents)], 2, 5, pos=True)\n",
    "print(len(vocab))\n",
    "print(vocab)\n",
    "vectorizer = CountVectorizer(vocabulary=[x.lower() for  x in vocab])\n",
    "print([' '.join(get_pos(text)) for text in train_sents])\n",
    "\n",
    "train_data = vectorizer.fit_transform([' '.join(get_pos(text)) for text in train_sents])\n",
    "print(vectorizer.get_feature_names())\n",
    "train_data = train_data.astype(float)\n",
    "print(train_data.shape)\n",
    "print(train_data.toarray())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem00001\n",
      "\t language:  en\n",
      "\t 20 candidate authors\n",
      "\t 140 known texts\n",
      "Do cross validation.\n",
      "(100, 52773)\n",
      "\t pos vocabulary size: 806 char vocabulary size: 52773\n",
      "lexical diversity: (100, 1)\n",
      "[ 21.  25.   6.  37.  39.  52.  16.  48.  59.  49.  99.  85.  47.  55.\n",
      "  49.  50.  37.  31.  42.  61.  87.  31.  40.  24.  59.  46.  43.  68.\n",
      "  47.  85.  42. 120.  94. 110. 127. 107.  31.  59. 108.  95.  77.  80.\n",
      "  75. 118.  98.  32.  54.  46.  64.  46.  54.  47.  86.  52.  68.  78.\n",
      "  57.  77.  90.  77.  62.  54.  55.  74.  86.  55.  55.  34.  61.  28.\n",
      "  70.  57.  44.  40.  66.  16.  13.  42.  21.  68.  62.  42. 105.  84.\n",
      "  38.  92.  93.  91.  87. 107.  45.  88.  57. 103.  65.  67.  38.  49.\n",
      "  73.  76.]\n",
      "pos data: (100, 806) char data: (100, 52773) word data: (100, 116893)\n",
      "lexical diversity: (40, 1)\n",
      "train shape: (100, 170473) test shape: (40, 170473)\n",
      "training before feature selection: (100, 170473)\n",
      "testing before feature selection: (40, 170473)\n",
      "training after feature selection: (100, 144902)\n",
      "testing after feature selection: (40, 144902)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred y_test: (40,) (40,)\n",
      "['candidate00013' 'candidate00013' 'candidate00012' 'candidate00013'\n",
      " 'candidate00013' 'candidate00013' 'candidate00013' 'candidate00013'\n",
      " 'candidate00013' 'candidate00013' 'candidate00012' 'candidate00013'\n",
      " 'candidate00013' 'candidate00013' 'candidate00013' 'candidate00013'\n",
      " 'candidate00012' 'candidate00012' 'candidate00013' 'candidate00013'\n",
      " 'candidate00013' 'candidate00013' 'candidate00013' 'candidate00013'\n",
      " 'candidate00013' 'candidate00013' 'candidate00013' 'candidate00013'\n",
      " 'candidate00013' 'candidate00013' 'candidate00013' 'candidate00013'\n",
      " 'candidate00013' 'candidate00013' 'candidate00012' 'candidate00013'\n",
      " 'candidate00013' 'candidate00013' 'candidate00012' 'candidate00013']\n",
      "['candidate00001' 'candidate00001' 'candidate00002' 'candidate00002'\n",
      " 'candidate00003' 'candidate00003' 'candidate00004' 'candidate00004'\n",
      " 'candidate00005' 'candidate00005' 'candidate00006' 'candidate00006'\n",
      " 'candidate00007' 'candidate00007' 'candidate00008' 'candidate00008'\n",
      " 'candidate00009' 'candidate00009' 'candidate00010' 'candidate00010'\n",
      " 'candidate00011' 'candidate00011' 'candidate00012' 'candidate00012'\n",
      " 'candidate00013' 'candidate00013' 'candidate00014' 'candidate00014'\n",
      " 'candidate00015' 'candidate00015' 'candidate00016' 'candidate00016'\n",
      " 'candidate00017' 'candidate00017' 'candidate00018' 'candidate00018'\n",
      " 'candidate00019' 'candidate00019' 'candidate00020' 'candidate00020']\n",
      "accuracy: 0.05\n",
      "(100, 52929)\n",
      "\t pos vocabulary size: 807 char vocabulary size: 52929\n",
      "lexical diversity: (100, 1)\n",
      "[ 63.  80.  74.  79.  72.  64.  76.  87.  74.  74. 101. 104. 103. 101.\n",
      "  95.  87.  79. 102. 103.  80.  77. 111. 115.  82. 111.  39.  45.  73.\n",
      "  73.  59.  92.  59.  73.  81.  76.  75.  72.  95.  85.  63.  66.  74.\n",
      "  89.  81.  67. 100.  75.  89.  78. 100.  79.  82.  73.  97.  71.  86.\n",
      "  85.  97.  87. 100. 100.  55.  62.  68.  74.  98.  84. 103.  74. 103.\n",
      "  98. 116.  62.  86.  78.  68.  73.  49.  69.  81.  58.  74.  75.  76.\n",
      "  63.  90. 101.  84.  94.  83.  80.  83.  61.  80.  88.  64.  78. 109.\n",
      "  71.  87.]\n",
      "pos data: (100, 807) char data: (100, 52929) word data: (100, 116940)\n",
      "lexical diversity: (40, 1)\n",
      "train shape: (100, 170677) test shape: (40, 170677)\n",
      "training before feature selection: (100, 170677)\n",
      "testing before feature selection: (40, 170677)\n",
      "training after feature selection: (100, 144495)\n",
      "testing after feature selection: (40, 144495)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred y_test: (40,) (40,)\n",
      "['candidate00005' 'candidate00005' 'candidate00005' 'candidate00005'\n",
      " 'candidate00005' 'candidate00005' 'candidate00005' 'candidate00005'\n",
      " 'candidate00005' 'candidate00005' 'candidate00005' 'candidate00005'\n",
      " 'candidate00005' 'candidate00005' 'candidate00014' 'candidate00005'\n",
      " 'candidate00005' 'candidate00005' 'candidate00005' 'candidate00005'\n",
      " 'candidate00005' 'candidate00005' 'candidate00005' 'candidate00005'\n",
      " 'candidate00005' 'candidate00005' 'candidate00005' 'candidate00005'\n",
      " 'candidate00005' 'candidate00005' 'candidate00005' 'candidate00005'\n",
      " 'candidate00005' 'candidate00005' 'candidate00005' 'candidate00005'\n",
      " 'candidate00005' 'candidate00005' 'candidate00005' 'candidate00005']\n",
      "['candidate00001' 'candidate00001' 'candidate00002' 'candidate00002'\n",
      " 'candidate00003' 'candidate00003' 'candidate00004' 'candidate00004'\n",
      " 'candidate00005' 'candidate00005' 'candidate00006' 'candidate00006'\n",
      " 'candidate00007' 'candidate00007' 'candidate00008' 'candidate00008'\n",
      " 'candidate00009' 'candidate00009' 'candidate00010' 'candidate00010'\n",
      " 'candidate00011' 'candidate00011' 'candidate00012' 'candidate00012'\n",
      " 'candidate00013' 'candidate00013' 'candidate00014' 'candidate00014'\n",
      " 'candidate00015' 'candidate00015' 'candidate00016' 'candidate00016'\n",
      " 'candidate00017' 'candidate00017' 'candidate00018' 'candidate00018'\n",
      " 'candidate00019' 'candidate00019' 'candidate00020' 'candidate00020']\n",
      "accuracy: 0.05\n",
      "(120, 58556)\n",
      "\t pos vocabulary size: 826 char vocabulary size: 58556\n",
      "lexical diversity: (120, 1)\n",
      "[ 63.  80.  70.  71.  79.  72.  64.  76.  97.  98.  74.  74. 101. 104.\n",
      " 106. 112. 101.  95.  87.  79.  64.  69. 103.  80.  77. 111.  87.  85.\n",
      "  82. 111.  39.  45.  72.  61.  73.  59.  92.  59.  78.  64.  81.  76.\n",
      "  75.  72.  95.  67.  85.  63.  66.  74.  84.  73.  81.  67. 100.  75.\n",
      "  62.  49.  78. 100.  79.  82.  69.  89.  97.  71.  86.  85. 104.  99.\n",
      "  87. 100. 100.  55.  75.  67.  68.  74.  98.  84.  91.  96.  74. 103.\n",
      "  98. 116.  56.  77.  86.  78.  68.  73.  70.  76.  69.  81.  58.  74.\n",
      "  66.  87.  76.  63.  90. 101.  77.  79.  94.  83.  80.  83.  56.  85.\n",
      "  80.  88.  64.  78.  84.  95.  71.  87.]\n",
      "pos data: (120, 826) char data: (120, 58556) word data: (120, 137457)\n",
      "lexical diversity: (20, 1)\n",
      "train shape: (120, 196840) test shape: (20, 196840)\n",
      "training before feature selection: (120, 196840)\n",
      "testing before feature selection: (20, 196840)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training after feature selection: (120, 167314)\n",
      "testing after feature selection: (20, 167314)\n",
      "y_pred y_test: (20,) (20,)\n",
      "['candidate00018' 'candidate00017' 'candidate00020' 'candidate00017'\n",
      " 'candidate00018' 'candidate00020' 'candidate00017' 'candidate00018'\n",
      " 'candidate00017' 'candidate00010' 'candidate00017' 'candidate00020'\n",
      " 'candidate00017' 'candidate00018' 'candidate00017' 'candidate00013'\n",
      " 'candidate00020' 'candidate00018' 'candidate00017' 'candidate00018']\n",
      "['candidate00001' 'candidate00002' 'candidate00003' 'candidate00004'\n",
      " 'candidate00005' 'candidate00006' 'candidate00007' 'candidate00008'\n",
      " 'candidate00009' 'candidate00010' 'candidate00011' 'candidate00012'\n",
      " 'candidate00013' 'candidate00014' 'candidate00015' 'candidate00016'\n",
      " 'candidate00017' 'candidate00018' 'candidate00019' 'candidate00020']\n",
      "accuracy: 0.1\n",
      "(120, 58489)\n",
      "\t pos vocabulary size: 831 char vocabulary size: 58489\n",
      "lexical diversity: (120, 1)\n",
      "[ 63.  80.  70.  71.  74.  72.  64.  76.  97.  98.  87.  74. 101. 104.\n",
      " 106. 112. 103.  95.  87.  79.  64.  69. 102.  80.  77. 111.  87.  85.\n",
      " 115. 111.  39.  45.  72.  61.  73.  59.  92.  59.  78.  64.  73.  76.\n",
      "  75.  72.  95.  67.  95.  63.  66.  74.  84.  73.  89.  67. 100.  75.\n",
      "  62.  49.  89. 100.  79.  82.  69.  89.  73.  71.  86.  85. 104.  99.\n",
      "  97. 100. 100.  55.  75.  67.  62.  74.  98.  84.  91.  96. 103. 103.\n",
      "  98. 116.  56.  77.  62.  78.  68.  73.  70.  76.  49.  81.  58.  74.\n",
      "  66.  87.  75.  63.  90. 101.  77.  79.  84.  83.  80.  83.  56.  85.\n",
      "  61.  88.  64.  78.  84.  95. 109.  87.]\n",
      "pos data: (120, 831) char data: (120, 58489) word data: (120, 137690)\n",
      "lexical diversity: (20, 1)\n",
      "train shape: (120, 197011) test shape: (20, 197011)\n",
      "training before feature selection: (120, 197011)\n",
      "testing before feature selection: (20, 197011)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training after feature selection: (120, 167459)\n",
      "testing after feature selection: (20, 167459)\n",
      "y_pred y_test: (20,) (20,)\n",
      "['candidate00020' 'candidate00016' 'candidate00020' 'candidate00020'\n",
      " 'candidate00016' 'candidate00020' 'candidate00020' 'candidate00020'\n",
      " 'candidate00020' 'candidate00016' 'candidate00015' 'candidate00016'\n",
      " 'candidate00020' 'candidate00020' 'candidate00020' 'candidate00020'\n",
      " 'candidate00020' 'candidate00016' 'candidate00016' 'candidate00016']\n",
      "['candidate00001' 'candidate00002' 'candidate00003' 'candidate00004'\n",
      " 'candidate00005' 'candidate00006' 'candidate00007' 'candidate00008'\n",
      " 'candidate00009' 'candidate00010' 'candidate00011' 'candidate00012'\n",
      " 'candidate00013' 'candidate00014' 'candidate00015' 'candidate00016'\n",
      " 'candidate00017' 'candidate00018' 'candidate00019' 'candidate00020']\n",
      "accuracy: 0.0\n",
      "(120, 58686)\n",
      "\t pos vocabulary size: 835 char vocabulary size: 58686\n",
      "lexical diversity: (120, 1)\n",
      "[ 63.  80.  70.  71.  74.  79.  64.  76.  97.  98.  87.  74. 101. 104.\n",
      " 106. 112. 103. 101.  87.  79.  64.  69. 102. 103.  77. 111.  87.  85.\n",
      " 115.  82.  39.  45.  72.  61.  73.  73.  92.  59.  78.  64.  73.  81.\n",
      "  75.  72.  95.  67.  95.  85.  66.  74.  84.  73.  89.  81. 100.  75.\n",
      "  62.  49.  89.  78.  79.  82.  69.  89.  73.  97.  86.  85. 104.  99.\n",
      "  97.  87. 100.  55.  75.  67.  62.  68.  98.  84.  91.  96. 103.  74.\n",
      "  98. 116.  56.  77.  62.  86.  68.  73.  70.  76.  49.  69.  58.  74.\n",
      "  66.  87.  75.  76.  90. 101.  77.  79.  84.  94.  80.  83.  56.  85.\n",
      "  61.  80.  64.  78.  84.  95. 109.  71.]\n",
      "pos data: (120, 835) char data: (120, 58686) word data: (120, 137858)\n",
      "lexical diversity: (20, 1)\n",
      "train shape: (120, 197380) test shape: (20, 197380)\n",
      "training before feature selection: (120, 197380)\n",
      "testing before feature selection: (20, 197380)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training after feature selection: (120, 167773)\n",
      "testing after feature selection: (20, 167773)\n",
      "y_pred y_test: (20,) (20,)\n",
      "['candidate00004' 'candidate00004' 'candidate00004' 'candidate00014'\n",
      " 'candidate00014' 'candidate00014' 'candidate00004' 'candidate00004'\n",
      " 'candidate00009' 'candidate00004' 'candidate00004' 'candidate00004'\n",
      " 'candidate00014' 'candidate00004' 'candidate00014' 'candidate00004'\n",
      " 'candidate00004' 'candidate00004' 'candidate00004' 'candidate00004']\n",
      "['candidate00001' 'candidate00002' 'candidate00003' 'candidate00004'\n",
      " 'candidate00005' 'candidate00006' 'candidate00007' 'candidate00008'\n",
      " 'candidate00009' 'candidate00010' 'candidate00011' 'candidate00012'\n",
      " 'candidate00013' 'candidate00014' 'candidate00015' 'candidate00016'\n",
      " 'candidate00017' 'candidate00018' 'candidate00019' 'candidate00020']\n",
      "accuracy: 0.05\n",
      "problem00001 MEAN ACCURACY SCORES: 0.05\n",
      "problem00002\n",
      "\t language:  en\n",
      "\t 5 candidate authors\n",
      "\t 35 known texts\n",
      "Do cross validation.\n",
      "(25, 20940)\n",
      "\t pos vocabulary size: 559 char vocabulary size: 20940\n",
      "lexical diversity: (25, 1)\n",
      "[74. 71. 62. 51. 70. 36. 56. 62. 73. 68. 36. 43. 40. 38. 37. 79. 62. 54.\n",
      " 61. 53. 49. 65. 59. 84. 55.]\n",
      "pos data: (25, 559) char data: (25, 20940) word data: (25, 32487)\n",
      "lexical diversity: (10, 1)\n",
      "train shape: (25, 53987) test shape: (10, 53987)\n",
      "training before feature selection: (25, 53987)\n",
      "testing before feature selection: (10, 53987)\n",
      "training after feature selection: (25, 45888)\n",
      "testing after feature selection: (10, 45888)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred y_test: (10,) (10,)\n",
      "['candidate00004' 'candidate00004' 'candidate00002' 'candidate00005'\n",
      " 'candidate00005' 'candidate00005' 'candidate00004' 'candidate00005'\n",
      " 'candidate00005' 'candidate00005']\n",
      "['candidate00001' 'candidate00001' 'candidate00002' 'candidate00002'\n",
      " 'candidate00003' 'candidate00003' 'candidate00004' 'candidate00004'\n",
      " 'candidate00005' 'candidate00005']\n",
      "accuracy: 0.4\n",
      "(25, 21107)\n",
      "\t pos vocabulary size: 573 char vocabulary size: 21107\n",
      "lexical diversity: (25, 1)\n",
      "[29. 40. 41. 37. 29. 12. 28. 11. 25. 12. 40. 17. 43. 16. 31. 33. 18. 31.\n",
      " 38. 47. 28. 25. 18. 39. 24.]\n",
      "pos data: (25, 573) char data: (25, 21107) word data: (25, 32519)\n",
      "lexical diversity: (10, 1)\n",
      "train shape: (25, 54200) test shape: (10, 54200)\n",
      "training before feature selection: (25, 54200)\n",
      "testing before feature selection: (10, 54200)\n",
      "training after feature selection: (25, 46070)\n",
      "testing after feature selection: (10, 46070)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred y_test: (10,) (10,)\n",
      "['candidate00001' 'candidate00001' 'candidate00005' 'candidate00004'\n",
      " 'candidate00005' 'candidate00004' 'candidate00005' 'candidate00005'\n",
      " 'candidate00005' 'candidate00005']\n",
      "['candidate00001' 'candidate00001' 'candidate00002' 'candidate00002'\n",
      " 'candidate00003' 'candidate00003' 'candidate00004' 'candidate00004'\n",
      " 'candidate00005' 'candidate00005']\n",
      "accuracy: 0.4\n",
      "(30, 24171)\n",
      "\t pos vocabulary size: 596 char vocabulary size: 24171\n",
      "lexical diversity: (30, 1)\n",
      "[29. 40. 36. 24. 37. 29. 12. 28. 19. 12. 25. 12. 40. 17. 39. 13. 16. 31.\n",
      " 33. 18. 40. 43. 38. 47. 28. 25. 20. 33. 39. 24.]\n",
      "pos data: (30, 596) char data: (30, 24171) word data: (30, 38451)\n",
      "lexical diversity: (5, 1)\n",
      "train shape: (30, 63219) test shape: (5, 63219)\n",
      "training before feature selection: (30, 63219)\n",
      "testing before feature selection: (5, 63219)\n",
      "training after feature selection: (30, 49363)\n",
      "testing after feature selection: (5, 49363)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred y_test: (5,) (5,)\n",
      "['candidate00001' 'candidate00005' 'candidate00003' 'candidate00001'\n",
      " 'candidate00005']\n",
      "['candidate00001' 'candidate00002' 'candidate00003' 'candidate00004'\n",
      " 'candidate00005']\n",
      "accuracy: 0.6\n",
      "(30, 23884)\n",
      "\t pos vocabulary size: 592 char vocabulary size: 23884\n",
      "lexical diversity: (30, 1)\n",
      "[29. 40. 36. 24. 41. 29. 12. 28. 19. 12. 11. 12. 40. 17. 39. 13. 43. 31.\n",
      " 33. 18. 40. 43. 31. 47. 28. 25. 20. 33. 18. 24.]\n",
      "pos data: (30, 592) char data: (30, 23884) word data: (30, 38443)\n",
      "lexical diversity: (5, 1)\n",
      "train shape: (30, 62920) test shape: (5, 62920)\n",
      "training before feature selection: (30, 62920)\n",
      "testing before feature selection: (5, 62920)\n",
      "training after feature selection: (30, 53482)\n",
      "testing after feature selection: (5, 53482)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred y_test: (5,) (5,)\n",
      "['candidate00004' 'candidate00004' 'candidate00004' 'candidate00004'\n",
      " 'candidate00004']\n",
      "['candidate00001' 'candidate00002' 'candidate00003' 'candidate00004'\n",
      " 'candidate00005']\n",
      "accuracy: 0.2\n",
      "(30, 24084)\n",
      "\t pos vocabulary size: 601 char vocabulary size: 24084\n",
      "lexical diversity: (30, 1)\n",
      "[29. 40. 36. 24. 41. 37. 12. 28. 19. 12. 11. 25. 40. 17. 39. 13. 43. 16.\n",
      " 33. 18. 40. 43. 31. 38. 28. 25. 20. 33. 18. 39.]\n",
      "pos data: (30, 601) char data: (30, 24084) word data: (30, 38670)\n",
      "lexical diversity: (5, 1)\n",
      "train shape: (30, 63356) test shape: (5, 63356)\n",
      "training before feature selection: (30, 63356)\n",
      "testing before feature selection: (5, 63356)\n",
      "training after feature selection: (30, 53852)\n",
      "testing after feature selection: (5, 53852)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred y_test: (5,) (5,)\n",
      "['candidate00001' 'candidate00003' 'candidate00003' 'candidate00001'\n",
      " 'candidate00005']\n",
      "['candidate00001' 'candidate00002' 'candidate00003' 'candidate00004'\n",
      " 'candidate00005']\n",
      "accuracy: 0.6\n",
      "problem00002 MEAN ACCURACY SCORES: 0.43999999999999995\n",
      "MEAN SCORES ACCROSS PROBLEMS: 0.24499999999999997\n",
      "elapsed time: 484.9901819229126\n"
     ]
    }
   ],
   "source": [
    "class Feature_Extractor():\n",
    "    '''\n",
    "    Performs feature extraction on input docs.\n",
    "    '''\n",
    "    def __init__(self, n, ft):\n",
    "        self.n = n\n",
    "        self.ft = ft\n",
    "        \n",
    "    def fit_transform(self, docs):\n",
    "        ## Char-level n-grams ##\n",
    "        char_vocab = extract_vocabulary(docs,self.n,self.ft)\n",
    "        self.char_vectorizer = CountVectorizer(analyzer='char', ngram_range=(self.n,self.n),\n",
    "                                          lowercase=False, vocabulary=char_vocab\n",
    "                                              )\n",
    "        char_data, self.char_vectorizer = self._fit_transform(self.char_vectorizer, docs)\n",
    "        print(char_data.shape)\n",
    "        # print(char_data.toarray())\n",
    "\n",
    "        ## POS n-grams ##\n",
    "        pos_vocab = [x.lower() for x in extract_vocabulary(docs,2,self.ft,pos=True)]\n",
    "        # print(pos_vocab)\n",
    "        self.pos_vectorizer = CountVectorizer(ngram_range=(1,2), vocabulary=pos_vocab\n",
    "                                             )\n",
    "        print('\\t', 'pos vocabulary size:', len(pos_vocab), 'char vocabulary size:', len(char_vocab))\n",
    "        pos_data, self.pos_vectorizer = self._fit_transform(self.pos_vectorizer, docs, pos_replace=True)\n",
    "        \n",
    "        ## Word n-grams ##\n",
    "        self.word_vectorizer = CountVectorizer(ngram_range=(2,3))\n",
    "        word_data, self.word_vectorizer = self._fit_transform(self.word_vectorizer, docs)\n",
    "        \n",
    "        ## Lexical Diversity\n",
    "        lex_div = self.lexical_diversity(docs)\n",
    "        print(pos_data.toarray()[:,1])\n",
    "        print('pos data: %s char data: %s word data: %s'%(pos_data.shape, char_data.shape, word_data.shape))\n",
    "        feature_data = self.combine_features((lex_div, pos_data, char_data, word_data \n",
    "                                             )) \n",
    "        return feature_data\n",
    "    \n",
    "    def combine_features(self, feat_tuple):\n",
    "        feature_data = hstack(feat_tuple)\n",
    "        return feature_data\n",
    "    \n",
    "    def replace_words_POS(self, texts):\n",
    "        return [' '.join(get_pos(text)) for text in texts]\n",
    "    \n",
    "    def lexical_diversity(self, docs):\n",
    "        lex_div = np.array([len(set(text)) / len(text) for (text,label) in docs]).reshape(len(docs), 1)\n",
    "        print('lexical diversity:', lex_div.shape)\n",
    "        return lex_div\n",
    "    \n",
    "    def _fit_transform(self, vectorizer, docs, pos_replace=False):\n",
    "        texts = [text for i,(text,label) in enumerate(docs)]\n",
    "        if pos_replace is True:\n",
    "            texts = self.replace_words_POS(texts) # replace words in text with POS\n",
    "        vec_data = vectorizer.fit_transform(texts)\n",
    "        vec_data = vec_data.astype(float)\n",
    "        return vec_data, vectorizer\n",
    "    \n",
    "    def _transform(self, vectorizer, docs, pos_replace=False):\n",
    "        texts = [text for i,(text,label) in enumerate(docs)]\n",
    "        if pos_replace is True:\n",
    "            texts = self.replace_words_POS(texts) # replace words in text with POS\n",
    "        vec_data = vectorizer.transform(texts)\n",
    "        vec_data = vec_data.astype(float)\n",
    "        return vec_data\n",
    "    \n",
    "    def transform(self, docs):\n",
    "        char_data = self._transform(self.char_vectorizer, docs)\n",
    "        word_data = self._transform(self.word_vectorizer, docs)\n",
    "        pos_data = self._transform(self.pos_vectorizer, docs, pos_replace=True)\n",
    "        lex_div = self.lexical_diversity(docs)\n",
    "        feature_data = self.combine_features((lex_div, pos_data, char_data, word_data\n",
    "                                             )) \n",
    "        return feature_data\n",
    "        \n",
    "def write_results(path, problem, unk_folder, predictions):\n",
    "    # Saving output data\n",
    "    out_data=[]\n",
    "    unk_filelist = glob.glob(path+os.sep+problem+os.sep+unk_folder+os.sep+'*.txt')\n",
    "    pathlen=len(path+os.sep+problem+os.sep+unk_folder+os.sep)\n",
    "    for i,v in enumerate(predictions):\n",
    "        out_data.append({'unknown-text': unk_filelist[i][pathlen:], 'predicted-author': v})\n",
    "    with open(outpath+os.sep+'answers-'+problem+'.json', 'w') as f:\n",
    "        json.dump(out_data, f, indent=4)\n",
    "    print('\\t', 'answers saved to file','answers-'+problem+'.json')\n",
    "    \n",
    "\n",
    "def get_baseline_model_fn(num_in, num_out):\n",
    "    # initialize baseline model fn with num features and num predicted categories\n",
    "    def baseline_model():\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(8, input_dim=num_in, activation='relu'))\n",
    "        model.add(Dense(num_out, activation='softmax'))\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "    return baseline_model\n",
    "\n",
    "\n",
    "def baseline_keras(path, outpath, n=3, ft=5, pt=0.1, feature_selection=False, \n",
    "             open_set=False, c=1, feat_sel_percent=None, clf=None, calibration=True):\n",
    "    start_time = time.time()\n",
    "    # Reading information about the collection\n",
    "    infocollection = path+os.sep+'collection-info.json'\n",
    "    problems = []\n",
    "    language = []\n",
    "    with open(infocollection, 'r') as f:\n",
    "        for attrib in json.load(f):\n",
    "            problems.append(attrib['problem-name'])\n",
    "            language.append(attrib['language'])\n",
    "    problem_scores = []\n",
    "    for index,problem in enumerate(problems):\n",
    "        print(problem)\n",
    "        # Reading information about the problem\n",
    "        infoproblem = path+os.sep+problem+os.sep+'problem-info.json'\n",
    "        candidates = []\n",
    "        with open(infoproblem, 'r') as f:\n",
    "            fj = json.load(f)\n",
    "            unk_folder = fj['unknown-folder']\n",
    "            for attrib in fj['candidate-authors']:\n",
    "                candidates.append(attrib['author-name'])\n",
    "        # Building training set\n",
    "        docs=[]\n",
    "        for candidate in candidates:\n",
    "            docs.extend(read_files(path+os.sep+problem,candidate))\n",
    "        train_labels = np.array([label for i,(text,label) in enumerate(docs)])\n",
    "        print('\\t', 'language: ', language[index])\n",
    "        print('\\t', len(candidates), 'candidate authors')\n",
    "        print('\\t', len(docs), 'known texts')\n",
    "        \n",
    "        ###### Applying Classifiers #####\n",
    "        if calibration is True:\n",
    "            clf=CalibratedClassifierCV(OneVsRestClassifier(SVC(C=c)))\n",
    "        else:\n",
    "            clf=OneVsRestClassifier(SVC(C=c))\n",
    "        skf = StratifiedKFold(n_splits=5,random_state=442)\n",
    "        scores = []\n",
    "        print(\"Do cross validation.\")\n",
    "        for train_index, test_index in skf.split(docs, train_labels):\n",
    "            X_train_docs = [docs[i] for i in train_index]\n",
    "            X_test_docs = [docs[i] for i in test_index]\n",
    "            y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
    "            ##### Extract X features ####\n",
    "            feat_extractor = Feature_Extractor(n, ft)\n",
    "            X_train = feat_extractor.fit_transform(X_train_docs)\n",
    "            X_test = feat_extractor.transform(X_test_docs)\n",
    "            print('train shape:', X_train.shape, 'test shape:', X_test.shape)\n",
    "            if feature_selection is True:\n",
    "                ####### Feature Selection - Fit #######\n",
    "                print(\"training before feature selection:\", X_train.shape)\n",
    "                print(\"testing before feature selection:\", X_test.shape)\n",
    "                #sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "                #train_data = sel.fit_transform(train_data)\n",
    "                # We use the default selection function: the 10% most significant features\n",
    "                sel = SelectPercentile(f_classif, percentile=feat_sel_percent)\n",
    "                X_train = sel.fit_transform(X_train, y_train)\n",
    "                X_test = sel.transform(X_test)\n",
    "                #sel = SelectKBest(chi2, k=100000)\n",
    "                #train_data = sel.fit_transform(train_data, train_labels)\n",
    "                print(\"training after feature selection:\", X_train.shape)\n",
    "                print(\"testing after feature selection:\", X_test.shape)\n",
    "            max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "            X_train = max_abs_scaler.fit_transform(X_train)\n",
    "            X_test = max_abs_scaler.transform(X_test)\n",
    "            baseline_model = get_baseline_model_fn(X_train.shape[1], len(candidates))\n",
    "            clf = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)\n",
    "            ##### Convert y to 1-hot encoding ####\n",
    "            y_encoder = LabelEncoder()\n",
    "            y_train = y_encoder.fit_transform(y_train)\n",
    "            # convert integers to dummy variables (i.e. one hot encoded)\n",
    "            y_train = np_utils.to_categorical(y_train)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            print(\"y_pred y_test:\", y_pred.shape, y_test.shape)\n",
    "            y_pred = y_encoder.inverse_transform(y_pred)\n",
    "            print(y_pred)\n",
    "            print(y_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            scores.append(accuracy)\n",
    "            print('accuracy:', accuracy)\n",
    "            #write_results(path, problem, unk_folder, predictions)\n",
    "        mean_score = np.mean(scores)\n",
    "        print(problem, 'MEAN ACCURACY SCORES:', mean_score)\n",
    "        problem_scores.append(mean_score)\n",
    "    print('MEAN SCORES ACCROSS PROBLEMS:', np.mean(problem_scores))\n",
    "    # todo: also add stdev of scores\n",
    "    print('elapsed time:', time.time() - start_time)\n",
    "\n",
    "base_dir='pan18-cross-domain-authorship-attribution-training-dataset-2017-12-02'\n",
    "out_dir = base_dir+os.sep+'output-dir'\n",
    "eval_dir = base_dir+os.sep+'eval-dir'\n",
    "#params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': False, 'c':0.1, 'feat_sel_percent': None, 'clf': 'SVC'}\n",
    "params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': True, 'c':0.1, 'feat_sel_percent': 85, 'clf': 'SVC', 'calibration': True}\n",
    "#params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': True, 'c':1, 'feat_sel_percent': 85, 'clf': 'SVC'}\n",
    "#params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': True, 'c':10, 'feat_sel_percent': 85, 'clf': 'SVC'}\n",
    "baseline_keras(base_dir,out_dir,**params)\n",
    "%timeit\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem00001\n",
      "\t language:  en\n",
      "\t 20 candidate authors\n",
      "\t 140 known texts\n",
      "labels: ['candidate00001' 'candidate00001' 'candidate00001' 'candidate00001'\n",
      " 'candidate00001' 'candidate00001' 'candidate00002' 'candidate00002'\n",
      " 'candidate00002' 'candidate00002' 'candidate00002' 'candidate00002'\n",
      " 'candidate00003' 'candidate00003' 'candidate00003' 'candidate00003'\n",
      " 'candidate00003' 'candidate00003' 'candidate00004' 'candidate00004'\n",
      " 'candidate00004' 'candidate00004' 'candidate00004' 'candidate00004'\n",
      " 'candidate00005' 'candidate00005' 'candidate00005' 'candidate00005'\n",
      " 'candidate00005' 'candidate00005' 'candidate00006' 'candidate00006'\n",
      " 'candidate00006' 'candidate00006' 'candidate00006' 'candidate00006'\n",
      " 'candidate00007' 'candidate00007' 'candidate00007' 'candidate00007'\n",
      " 'candidate00007' 'candidate00007' 'candidate00008' 'candidate00008'\n",
      " 'candidate00008' 'candidate00008' 'candidate00008' 'candidate00008'\n",
      " 'candidate00009' 'candidate00009' 'candidate00009' 'candidate00009'\n",
      " 'candidate00009' 'candidate00009' 'candidate00010' 'candidate00010'\n",
      " 'candidate00010' 'candidate00010' 'candidate00010' 'candidate00010'\n",
      " 'candidate00011' 'candidate00011' 'candidate00011' 'candidate00011'\n",
      " 'candidate00011' 'candidate00011' 'candidate00012' 'candidate00012'\n",
      " 'candidate00012' 'candidate00012' 'candidate00012' 'candidate00012'\n",
      " 'candidate00013' 'candidate00013' 'candidate00013' 'candidate00013'\n",
      " 'candidate00013' 'candidate00013' 'candidate00014' 'candidate00014'\n",
      " 'candidate00014' 'candidate00014' 'candidate00014' 'candidate00014'\n",
      " 'candidate00015' 'candidate00015' 'candidate00015' 'candidate00015'\n",
      " 'candidate00015' 'candidate00015' 'candidate00016' 'candidate00016'\n",
      " 'candidate00016' 'candidate00016' 'candidate00016' 'candidate00016'\n",
      " 'candidate00017' 'candidate00017' 'candidate00017' 'candidate00017'\n",
      " 'candidate00017' 'candidate00017' 'candidate00018' 'candidate00018'\n",
      " 'candidate00018' 'candidate00018' 'candidate00018' 'candidate00018'\n",
      " 'candidate00019' 'candidate00019' 'candidate00019' 'candidate00019'\n",
      " 'candidate00019' 'candidate00019' 'candidate00020' 'candidate00020'\n",
      " 'candidate00020' 'candidate00020' 'candidate00020' 'candidate00020']\n",
      "(120, 58734)\n",
      "\t pos vocabulary size: 840 char vocabulary size: 58734\n",
      "lexical diversity: (120, 1)\n",
      "[20. 20. 13. 17. 27. 27. 27. 33. 34. 27. 27. 13. 29. 23. 22. 38. 29. 17.\n",
      " 34. 22. 19. 29. 43. 25. 36. 30. 39. 49. 25. 39. 21. 34. 22. 35. 21. 32.\n",
      " 15. 18. 14. 18. 19.  7. 32. 31. 23. 10. 20. 22. 16. 23. 28. 31. 43. 23.\n",
      " 20. 30. 15. 19. 34. 40. 34. 18. 24. 27. 25. 34. 21. 19. 27. 29. 17. 25.\n",
      " 11. 22. 18. 14. 27. 12. 11. 19. 30. 32. 21. 37. 30. 19. 35. 19.  9. 22.\n",
      " 29. 16. 25. 16. 12. 18. 17. 18. 30. 24. 31. 28. 26. 26. 27. 39. 33. 31.\n",
      " 24. 15. 34. 22. 32. 28. 23. 32. 24. 36. 27. 27.]\n",
      "pos data: (120, 840) char data: (120, 58734) word data: (120, 137899)\n",
      "lexical diversity: (20, 1)\n",
      "train shape: (120, 197474) test shape: (20, 197474)\n",
      "training before feature selection: (120, 197474)\n",
      "testing before feature selection: (20, 197474)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training after feature selection: (120, 167852)\n",
      "testing after feature selection: (20, 167852)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: ['candidate00001' 'candidate00001' 'candidate00001' 'candidate00001'\n",
      " 'candidate00001' 'candidate00001' 'candidate00002' 'candidate00002'\n",
      " 'candidate00002' 'candidate00002' 'candidate00002' 'candidate00002'\n",
      " 'candidate00003' 'candidate00003' 'candidate00003' 'candidate00003'\n",
      " 'candidate00003' 'candidate00003' 'candidate00004' 'candidate00004'\n",
      " 'candidate00004' 'candidate00004' 'candidate00004' 'candidate00004'\n",
      " 'candidate00005' 'candidate00005' 'candidate00005' 'candidate00005'\n",
      " 'candidate00005' 'candidate00005' 'candidate00006' 'candidate00006'\n",
      " 'candidate00006' 'candidate00006' 'candidate00006' 'candidate00006'\n",
      " 'candidate00007' 'candidate00007' 'candidate00007' 'candidate00007'\n",
      " 'candidate00007' 'candidate00007' 'candidate00008' 'candidate00008'\n",
      " 'candidate00008' 'candidate00008' 'candidate00008' 'candidate00008'\n",
      " 'candidate00009' 'candidate00009' 'candidate00009' 'candidate00009'\n",
      " 'candidate00009' 'candidate00009' 'candidate00010' 'candidate00010'\n",
      " 'candidate00010' 'candidate00010' 'candidate00010' 'candidate00010'\n",
      " 'candidate00011' 'candidate00011' 'candidate00011' 'candidate00011'\n",
      " 'candidate00011' 'candidate00011' 'candidate00012' 'candidate00012'\n",
      " 'candidate00012' 'candidate00012' 'candidate00012' 'candidate00012'\n",
      " 'candidate00013' 'candidate00013' 'candidate00013' 'candidate00013'\n",
      " 'candidate00013' 'candidate00013' 'candidate00014' 'candidate00014'\n",
      " 'candidate00014' 'candidate00014' 'candidate00014' 'candidate00014'\n",
      " 'candidate00015' 'candidate00015' 'candidate00015' 'candidate00015'\n",
      " 'candidate00015' 'candidate00015' 'candidate00016' 'candidate00016'\n",
      " 'candidate00016' 'candidate00016' 'candidate00016' 'candidate00016'\n",
      " 'candidate00017' 'candidate00017' 'candidate00017' 'candidate00017'\n",
      " 'candidate00017' 'candidate00017' 'candidate00018' 'candidate00018'\n",
      " 'candidate00018' 'candidate00018' 'candidate00018' 'candidate00018'\n",
      " 'candidate00019' 'candidate00019' 'candidate00019' 'candidate00019'\n",
      " 'candidate00019' 'candidate00019' 'candidate00020' 'candidate00020'\n",
      " 'candidate00020' 'candidate00020' 'candidate00020' 'candidate00020']\n",
      "(120, 58808)\n"
     ]
    }
   ],
   "source": [
    "def baseline_crossval(path, outpath, n=3, ft=5, pt=0.1, feature_selection=False, \n",
    "             open_set=False, c=1, feat_sel_percent=None, clf=None, calibration=True, clf_params={}):\n",
    "    start_time = time.time()\n",
    "    # Reading information about the collection\n",
    "    infocollection = path+os.sep+'collection-info.json'\n",
    "    problems = []\n",
    "    language = []\n",
    "    with open(infocollection, 'r') as f:\n",
    "        for attrib in json.load(f):\n",
    "            problems.append(attrib['problem-name'])\n",
    "            language.append(attrib['language'])\n",
    "    problem_scores = []\n",
    "    for index,problem in enumerate(problems):\n",
    "        print(problem)\n",
    "        # Reading information about the problem\n",
    "        infoproblem = path+os.sep+problem+os.sep+'problem-info.json'\n",
    "        candidates = []\n",
    "        with open(infoproblem, 'r') as f:\n",
    "            fj = json.load(f)\n",
    "            unk_folder = fj['unknown-folder']\n",
    "            for attrib in fj['candidate-authors']:\n",
    "                candidates.append(attrib['author-name'])\n",
    "        # Building training set\n",
    "        docs=[]\n",
    "        for candidate in candidates:\n",
    "            docs.extend(read_files(path+os.sep+problem,candidate))\n",
    "        train_labels = np.array([label for i,(text,label) in enumerate(docs)])\n",
    "        print('\\t', 'language: ', language[index])\n",
    "        print('\\t', len(candidates), 'candidate authors')\n",
    "        print('\\t', len(docs), 'known texts')\n",
    "        \n",
    "        ###### Applying Classifiers #####\n",
    "        if calibration is True:\n",
    "            clf=CalibratedClassifierCV(OneVsRestClassifier(clf(**clf_params)))\n",
    "        else:\n",
    "            clf=OneVsRestClassifier(clf(**clf_params))\n",
    "        skf = StratifiedKFold(n_splits=7,random_state=442)\n",
    "        scores = []\n",
    "        for train_index, test_index in skf.split(docs, train_labels):\n",
    "            X_train_docs = [docs[i] for i in train_index]\n",
    "            X_test_docs = [docs[i] for i in test_index]\n",
    "            y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
    "            feat_extractor = Feature_Extractor(n, ft)\n",
    "            print('labels:', y_train)\n",
    "            X_train = feat_extractor.fit_transform(X_train_docs)\n",
    "            X_test = feat_extractor.transform(X_test_docs)\n",
    "            print('train shape:', X_train.shape, 'test shape:', X_test.shape)\n",
    "            if feature_selection is True:\n",
    "                ####### Feature Selection - Fit #######\n",
    "                print(\"training before feature selection:\", X_train.shape)\n",
    "                print(\"testing before feature selection:\", X_test.shape)\n",
    "                #sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "                #train_data = sel.fit_transform(train_data)\n",
    "                # We use the default selection function: the 10% most significant features\n",
    "                sel = SelectPercentile(f_classif, percentile=feat_sel_percent)\n",
    "                X_train = sel.fit_transform(X_train, y_train)\n",
    "                X_test = sel.transform(X_test)\n",
    "                #sel = SelectKBest(chi2, k=100000)\n",
    "                #train_data = sel.fit_transform(train_data, train_labels)\n",
    "                print(\"training after feature selection:\", X_train.shape)\n",
    "                print(\"testing after feature selection:\", X_test.shape)\n",
    "            max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "            X_train = max_abs_scaler.fit_transform(X_train)\n",
    "            X_test = max_abs_scaler.transform(X_test)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            scores.append(accuracy_score(y_test, y_pred))\n",
    "            #write_results(path, problem, unk_folder, predictions)\n",
    "        mean_score = np.mean(scores)\n",
    "        print(problem, 'MEAN ACCURACY SCORES:', mean_score)\n",
    "        problem_scores.append(mean_score)\n",
    "    print('MEAN SCORES ACCROSS PROBLEMS:', np.mean(problem_scores))\n",
    "    # todo: also add stdev of scores\n",
    "    print('elapsed time:', time.time() - start_time)\n",
    "\n",
    "base_dir='pan18-cross-domain-authorship-attribution-training-dataset-2017-12-02'\n",
    "out_dir = base_dir+os.sep+'output-dir'\n",
    "eval_dir = base_dir+os.sep+'eval-dir'\n",
    "#params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': False, 'c':0.1, 'feat_sel_percent': None, 'clf': 'SVC'}\n",
    "params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': True, 'clf_params': {'C': 0.1}, 'feat_sel_percent': 85, 'clf': SVC, 'calibration': True}\n",
    "#params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': True, 'c':1, 'feat_sel_percent': 85, 'clf': 'SVC'}\n",
    "#params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': True, 'c':10, 'feat_sel_percent': 85, 'clf': 'SVC'}\n",
    "baseline_crossval(base_dir,out_dir,**params)\n",
    "%timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': False, 'c':0.1, 'feat_sel_percent': None, 'clf': 'SVC'}\n",
    "params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': True, 'c':0.1, 'feat_sel_percent': 85, 'clf': 'SVC', 'calibration': True}\n",
    "#params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': True, 'c':1, 'feat_sel_percent': 85, 'clf': 'SVC'}\n",
    "#params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': True, 'c':10, 'feat_sel_percent': 85, 'clf': 'SVC'}\n",
    "baseline(base_dir,out_dir,**params)\n",
    "%timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem00001\n",
      "(140, 64239)\n",
      "\t pos vocabulary size: 861 char vocabulary size: 64239\n",
      "lexical diversity: (140, 1)\n",
      "[ 63.  80.  70.  71.  74.  79.  72.  64.  76.  97.  98.  87.  74.  74.\n",
      " 101. 104. 106. 112. 103. 101.  95.  87.  79.  64.  69. 102. 103.  80.\n",
      "  77. 111.  87.  85. 115.  82. 111.  39.  45.  72.  61.  73.  73.  59.\n",
      "  92.  59.  78.  64.  73.  81.  76.  75.  72.  95.  67.  95.  85.  63.\n",
      "  66.  74.  84.  73.  89.  81.  67. 100.  75.  62.  49.  89.  78. 100.\n",
      "  79.  82.  69.  89.  73.  97.  71.  86.  85. 104.  99.  97.  87. 100.\n",
      " 100.  55.  75.  67.  62.  68.  74.  98.  84.  91.  96. 103.  74. 103.\n",
      "  98. 116.  56.  77.  62.  86.  78.  68.  73.  70.  76.  49.  69.  81.\n",
      "  58.  74.  66.  87.  75.  76.  63.  90. 101.  77.  79.  84.  94.  83.\n",
      "  80.  83.  56.  85.  61.  80.  88.  64.  78.  84.  95. 109.  71.  87.]\n",
      "pos data: (140, 861) char data: (140, 64239) word data: (140, 158555)\n",
      "training before feature selection: (140, 223656)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training after feature selection: (140, 190107)\n",
      "\t language:  en\n",
      "\t 20 candidate authors\n",
      "\t 140 known texts\n",
      "lexical diversity: (105, 1)\n",
      "test before feature selection: (105, 223656)\n",
      "test after feature selection: (105, 190107)\n",
      "\t 105 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t answers saved to file answers-problem00001.json\n",
      "problem00002\n",
      "(35, 26761)\n",
      "\t pos vocabulary size: 619 char vocabulary size: 26761\n",
      "lexical diversity: (35, 1)\n",
      "[29. 40. 36. 24. 41. 37. 29. 12. 28. 19. 12. 11. 25. 12. 40. 17. 39. 13.\n",
      " 43. 16. 31. 33. 18. 40. 43. 31. 38. 47. 28. 25. 20. 33. 18. 39. 24.]\n",
      "pos data: (35, 619) char data: (35, 26761) word data: (35, 44504)\n",
      "training before feature selection: (35, 71885)\n",
      "training after feature selection: (35, 56848)\n",
      "\t language:  en\n",
      "\t 5 candidate authors\n",
      "\t 35 known texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [0 0 0 ... 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lexical diversity: (21, 1)\n",
      "test before feature selection: (21, 71885)\n",
      "test after feature selection: (21, 56848)\n",
      "\t 21 unknown texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t answers saved to file answers-problem00002.json\n",
      "elapsed time: 42.82914471626282\n"
     ]
    }
   ],
   "source": [
    "def baseline_old(path, outpath, n=3, ft=5, pt=0.1, feature_selection=False, \n",
    "             open_set=False, c=1, feat_sel_percent=None, clf=None):\n",
    "    start_time = time.time()\n",
    "    # Reading information about the collection\n",
    "    infocollection = path+os.sep+'collection-info.json'\n",
    "    problems = []\n",
    "    language = []\n",
    "    with open(infocollection, 'r') as f:\n",
    "        for attrib in json.load(f):\n",
    "            problems.append(attrib['problem-name'])\n",
    "            language.append(attrib['language'])\n",
    "    for index,problem in enumerate(problems):\n",
    "        print(problem)\n",
    "        # Reading information about the problem\n",
    "        infoproblem = path+os.sep+problem+os.sep+'problem-info.json'\n",
    "        candidates = []\n",
    "        with open(infoproblem, 'r') as f:\n",
    "            fj = json.load(f)\n",
    "            unk_folder = fj['unknown-folder']\n",
    "            for attrib in fj['candidate-authors']:\n",
    "                candidates.append(attrib['author-name'])\n",
    "        # Building training set\n",
    "        train_docs=[]\n",
    "        for candidate in candidates:\n",
    "            train_docs.extend(read_files(path+os.sep+problem,candidate))\n",
    "        train_labels = [label for i,(text,label) in enumerate(train_docs)]\n",
    "        #### Feature Extraction ###\n",
    "        ###### Fit-Transform Training Set #######\n",
    "        feat_extractor = Feature_Extractor(n, ft)\n",
    "        train_data = feat_extractor.fit_transform(train_docs)\n",
    "        if feature_selection is True:\n",
    "            ####### Feature Selection - Fit #######\n",
    "            print(\"training before feature selection:\", train_data.shape)\n",
    "            #sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "            #train_data = sel.fit_transform(train_data)\n",
    "            # We use the default selection function: the 10% most significant features\n",
    "            sel = SelectPercentile(f_classif, percentile=feat_sel_percent)\n",
    "            train_data = sel.fit_transform(train_data, train_labels)\n",
    "            #sel = SelectKBest(chi2, k=100000)\n",
    "            #train_data = sel.fit_transform(train_data, train_labels)\n",
    "            print(\"training after feature selection:\", train_data.shape)\n",
    "        print('\\t', 'language: ', language[index])\n",
    "        print('\\t', len(candidates), 'candidate authors')\n",
    "        print('\\t', len(train_docs), 'known texts')\n",
    "        \n",
    "        ###### Transform Test Set #######\n",
    "        test_docs=read_files(path+os.sep+problem,unk_folder)\n",
    "        test_data = feat_extractor.transform(test_docs)\n",
    "        if feature_selection is True:\n",
    "            ####### Feature Selection #######\n",
    "            print(\"test before feature selection:\", test_data.shape)\n",
    "            test_data = sel.transform(test_data)\n",
    "            print(\"test after feature selection:\", test_data.shape)\n",
    "        print('\\t', len(test_docs), 'unknown texts')\n",
    "        \n",
    "        ###### Applying Classifiers #####\n",
    "        max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "        scaled_train_data = max_abs_scaler.fit_transform(train_data)\n",
    "        scaled_test_data = max_abs_scaler.transform(test_data)\n",
    "        clf=CalibratedClassifierCV(OneVsRestClassifier(SVC(C=c)))\n",
    "        clf.fit(scaled_train_data, train_labels)\n",
    "        predictions=clf.predict(scaled_test_data)\n",
    "        proba=clf.predict_proba(scaled_test_data)\n",
    "        if open_set is True:\n",
    "            # Reject option (used in open-set cases)\n",
    "            count=0\n",
    "            for i,p in enumerate(predictions):\n",
    "                sproba=sorted(proba[i],reverse=True)\n",
    "                if sproba[0]-sproba[1]<pt:\n",
    "                    predictions[i]=u'<UNK>'\n",
    "                    count=count+1\n",
    "            print('\\t',count,'texts left unattributed')\n",
    "        # Saving output data\n",
    "        out_data=[]\n",
    "        unk_filelist = glob.glob(path+os.sep+problem+os.sep+unk_folder+os.sep+'*.txt')\n",
    "        pathlen=len(path+os.sep+problem+os.sep+unk_folder+os.sep)\n",
    "        for i,v in enumerate(predictions):\n",
    "            out_data.append({'unknown-text': unk_filelist[i][pathlen:], 'predicted-author': v})\n",
    "        with open(outpath+os.sep+'answers-'+problem+'.json', 'w') as f:\n",
    "            json.dump(out_data, f, indent=4)\n",
    "        print('\\t', 'answers saved to file','answers-'+problem+'.json')\n",
    "    print('elapsed time:', time.time() - start_time)\n",
    "\n",
    "base_dir='pan18-cross-domain-authorship-attribution-training-dataset-2017-12-02'\n",
    "out_dir = base_dir+os.sep+'output-dir'\n",
    "eval_dir = base_dir+os.sep+'eval-dir'\n",
    "params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': True, 'c':0.1, 'feat_sel_percent': 85, 'clf': 'SVC'}\n",
    "#params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': True, 'c':1, 'feat_sel_percent': 85, 'clf': 'SVC'}\n",
    "baseline_old(base_dir,out_dir,**params)\n",
    "%timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': True, 'c':0.1, 'feat_sel_percent': 85, 'clf': 'Keras Neural Network'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': True, 'c':0.1, 'feat_sel_percent': 85, 'clf': 'Keras Neural Network'}\n",
    "#params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': False, 'c':0.1, 'feat_sel_percent': None, 'clf': 'SVC'}\n",
    "#params = {'n': 5,'ft': 3,'pt': 0.05,'feature_selection': True, 'c':1, 'feat_sel_percent': 85, 'clf': 'SVC'}\n",
    "baseline_old(base_dir,out_dir,**params)\n",
    "%timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem00001 Macro-F1: 0.641\n",
      "problem00002 Macro-F1: 0.783\n",
      "Overall score: 0.712\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>ft</th>\n",
       "      <th>pt</th>\n",
       "      <th>feature_selection</th>\n",
       "      <th>c</th>\n",
       "      <th>feat_sel_percent</th>\n",
       "      <th>clf</th>\n",
       "      <th>calibration</th>\n",
       "      <th>problem-name</th>\n",
       "      <th>macro-f1</th>\n",
       "      <th>macro-precision</th>\n",
       "      <th>macro-recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>85</td>\n",
       "      <td>SVC</td>\n",
       "      <td>True</td>\n",
       "      <td>problem00001</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>85</td>\n",
       "      <td>SVC</td>\n",
       "      <td>True</td>\n",
       "      <td>problem00002</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>85</td>\n",
       "      <td>SVC</td>\n",
       "      <td>True</td>\n",
       "      <td>problem00001</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>85</td>\n",
       "      <td>SVC</td>\n",
       "      <td>True</td>\n",
       "      <td>problem00002</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>85</td>\n",
       "      <td>Keras Neural Network</td>\n",
       "      <td>problem00001</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.784</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>85</td>\n",
       "      <td>Keras Neural Network</td>\n",
       "      <td>problem00002</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.783</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n  ft    pt  feature_selection    c  feat_sel_percent  \\\n",
       "0  5   3  0.05               True  0.1                85   \n",
       "1  5   3  0.05               True  0.1                85   \n",
       "2  5   3  0.05               True  0.1                85   \n",
       "3  5   3  0.05               True  0.1                85   \n",
       "4  5   3  0.05               True  0.1                85   \n",
       "5  5   3  0.05               True  0.1                85   \n",
       "\n",
       "                    clf   calibration  problem-name  macro-f1  \\\n",
       "0                   SVC          True  problem00001     0.641   \n",
       "1                   SVC          True  problem00002     0.783   \n",
       "2                   SVC          True  problem00001     0.641   \n",
       "3                   SVC          True  problem00002     0.783   \n",
       "4  Keras Neural Network  problem00001         0.641     0.621   \n",
       "5  Keras Neural Network  problem00002         0.783     0.783   \n",
       "\n",
       "   macro-precision  macro-recall  \n",
       "0            0.621         0.784  \n",
       "1            0.783         0.783  \n",
       "2            0.621         0.784  \n",
       "3            0.783         0.783  \n",
       "4            0.784           NaN  \n",
       "5            0.783           NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "# Evaluation script for the Cross-Domain Authorship Attribution task @PAN2019.\n",
    "We use the F1 metric (macro-average) as implemented in scikit-learn:\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "We include the following ad hoc rules:\n",
    "- If authors are predicted which were not seen during training,\n",
    "  these predictions will count as false predictions ('<UNK>' class)\n",
    "  and they will negatively effect performance.\n",
    "- If texts are left unattributed they will assigned to the ('<UNK>'\n",
    "  class) and they will negatively effect performance.\n",
    "- The <UNK> class is excluded from the macro-average across classes.\n",
    "- If multiple test attributions are given for a single unknown document,\n",
    "  only the first one will be taken into consideration.\n",
    "\n",
    "Dependencies:\n",
    "- Python 2.7 or 3.6 (we recommend the Anaconda Python distribution)\n",
    "- scikit-learn\n",
    "\n",
    "Usage from the command line:\n",
    ">>> python pan19-cdaa-evaluator.py -i COLLECTION -a ANSWERS -o OUTPUT\n",
    "where\n",
    "    COLLECTION is the path to the main folder of the evaluation collection\n",
    "    ANSWERS is the path to the answers folder of a submitted method\n",
    "    OUTPUT is the path to the folder where the results of the evaluation will be saved\n",
    "\n",
    "Example: \n",
    ">>>  python pan19-cdaa-evaluator.py -i \".\\pan19-cross-domain-authorship-attribution-training-dataset-2019-01-23\\\" -a \".\\answ\n",
    "ers-unigram\" -o \".\\eval-unigram\\\"\n",
    "\n",
    "# References:\n",
    "@article{scikit-learn,\n",
    " title={Scikit-learn: Machine Learning in {P}ython},\n",
    " author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n",
    "         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n",
    "         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n",
    "         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n",
    " journal={Journal of Machine Learning Research},\n",
    " volume={12},\n",
    " pages={2825--2830},\n",
    " year={2011}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "def eval_measures(gt, pred):\n",
    "    \"\"\"Compute macro-averaged F1-scores, macro-averaged precision, \n",
    "    macro-averaged recall, and micro-averaged accuracy according the ad hoc\n",
    "    rules discussed at the top of this file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    gt : dict\n",
    "        Ground truth, where keys indicate text file names\n",
    "        (e.g. `unknown00002.txt`), and values represent\n",
    "        author labels (e.g. `candidate00003`)\n",
    "    pred : dict\n",
    "        Predicted attribution, where keys indicate text file names\n",
    "        (e.g. `unknown00002.txt`), and values represent\n",
    "        author labels (e.g. `candidate00003`)\n",
    "    Returns\n",
    "    -------\n",
    "    f1 : float\n",
    "        Macro-averaged F1-score\n",
    "    precision : float\n",
    "        Macro-averaged precision\n",
    "    recall : float\n",
    "        Macro-averaged recall\n",
    "    accuracy : float\n",
    "        Micro-averaged F1-score\n",
    "    \"\"\"\n",
    "\n",
    "    actual_authors = list(gt.values())\n",
    "    encoder = LabelEncoder().fit(['<UNK>'] + actual_authors)\n",
    "\n",
    "    text_ids, gold_authors, silver_authors = [], [], []\n",
    "    for text_id in sorted(gt):\n",
    "        text_ids.append(text_id)\n",
    "        gold_authors.append(gt[text_id])\n",
    "        try:\n",
    "            silver_authors.append(pred[text_id])\n",
    "        except KeyError:\n",
    "            # missing attributions get <UNK>:\n",
    "            silver_authors.append('<UNK>')\n",
    "\n",
    "    assert len(text_ids) == len(gold_authors)\n",
    "    assert len(text_ids) == len(silver_authors)\n",
    "\n",
    "    # replace non-existent silver authors with '<UNK>':\n",
    "    silver_authors = [a if a in encoder.classes_ else '<UNK>' \n",
    "                      for a in silver_authors]\n",
    "\n",
    "    gold_author_ints = encoder.transform(gold_authors)\n",
    "    silver_author_ints = encoder.transform(silver_authors)\n",
    "\n",
    "    # get F1 for individual classes (and suppress warnings):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        labels=list(set(gold_author_ints))\n",
    "        # Exclude the <UNK> class\n",
    "        for x in labels:\n",
    "            if encoder.inverse_transform(np.array([x]))=='<UNK>':\n",
    "                labels.remove(x)\n",
    "        f1 = f1_score(gold_author_ints,\n",
    "                  silver_author_ints,\n",
    "                  labels,\n",
    "                  average='macro')\n",
    "        precision = precision_score(gold_author_ints,\n",
    "                  silver_author_ints,\n",
    "                  labels,\n",
    "                  average='macro')\n",
    "        recall = recall_score(gold_author_ints,\n",
    "                  silver_author_ints,\n",
    "                  labels,\n",
    "                  average='macro')\n",
    "        accuracy = accuracy_score(gold_author_ints,\n",
    "                  silver_author_ints)\n",
    "\n",
    "    return f1,precision,recall\n",
    "\n",
    "def evaluate(ground_truth_file,predictions_file):\n",
    "    # Calculates evaluation measures for a single attribution problem\n",
    "    gt = {}\n",
    "    with open(ground_truth_file, 'r') as f:\n",
    "        for attrib in json.load(f)['ground_truth']:\n",
    "            gt[attrib['unknown-text']] = attrib['true-author']\n",
    "\n",
    "    pred = {}\n",
    "    with open(predictions_file, 'r') as f:\n",
    "        for attrib in json.load(f):\n",
    "            if attrib['unknown-text'] not in pred:\n",
    "                pred[attrib['unknown-text']] = attrib['predicted-author']\n",
    "    f1,precision,recall =  eval_measures(gt,pred)\n",
    "    return round(f1,3), round(precision,3), round(recall,3)\n",
    "\n",
    "def evaluate_all(path_collection,path_answers,path_out,params):\n",
    "    # Calculates evaluation measures for a PAN-18 collection of attribution problems\n",
    "    infocollection = path_collection+os.sep+'collection-info.json'\n",
    "    problems = []\n",
    "    data = []\n",
    "    with open(infocollection, 'r') as f:\n",
    "        for attrib in json.load(f):\n",
    "            problems.append(attrib['problem-name'])\n",
    "    scores=[];\n",
    "    for problem in problems:\n",
    "        prob_data = deepcopy(params)\n",
    "        f1,precision,recall=evaluate(path_collection+os.sep+problem+os.sep+'ground-truth.json',path_answers+os.sep+'answers-'+problem+'.json')\n",
    "        scores.append(f1)\n",
    "        prob_data.update({'problem-name': problem, 'macro-f1': round(f1,3), 'macro-precision': round(precision,3), 'macro-recall': round(recall,3)})\n",
    "        if os.path.isfile('metrics.csv'):\n",
    "            with open('metrics.csv', 'a') as f:  # Just use 'w' mode in 3.x\n",
    "                w = csv.DictWriter(f, prob_data.keys())\n",
    "                w.writerow(prob_data)\n",
    "        else:\n",
    "            with open('metrics.csv', 'w') as f:  # Just use 'w' mode in 3.x\n",
    "                w = csv.DictWriter(f, prob_data.keys())\n",
    "                w.writeheader()\n",
    "                w.writerow(prob_data)\n",
    "        data.append(prob_data)\n",
    "        print(str(problem),'Macro-F1:',round(f1,3))\n",
    "    overall_score=sum(scores)/len(scores)\n",
    "    # Saving data to output files (out.json and evaluation.prototext)\n",
    "    with open(path_out+os.sep+'out.json', 'w') as f:\n",
    "        json.dump({'problems': data, 'overall_score': round(overall_score,3)}, f, indent=4, sort_keys=True)\n",
    "    print('Overall score:', round(overall_score,3))\n",
    "    prototext='measure {\\n key: \"mean macro-f1\"\\n value: \"'+str(round(overall_score,3))+'\"\\n}\\n'\n",
    "    with open(path_out+os.sep+'evaluation.prototext', 'w') as f:\n",
    "        f.write(prototext)\n",
    "    return pd.read_csv('metrics.csv')\n",
    "        \n",
    "params\n",
    "evaluate_all(base_dir,out_dir,eval_dir, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('metrics.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('c', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['feature_selection'] == True].groupby(['problem-name'])['macro-recall', 'macro-precision'].plot(legend=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
