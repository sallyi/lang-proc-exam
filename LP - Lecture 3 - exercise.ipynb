{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural language model exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'head' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!head input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 163817 characters, 87 unique.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ufeffPr'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data I/O\n",
    "data = open('input.txt', 'r', encoding='utf8').read() # should be simple plain text file\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print ('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What did we just do?\n",
    "\n",
    "We just read the text character by character. Play a little bit with variables to make sure you understand what each of them has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal:\n",
    "\n",
    " - Let's make a Neural Language Model with a window size of 2\n",
    " \n",
    " - We will make a Language Model of characters, instead of words\n",
    "\n",
    " - We will only consider the previous two characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we learn out of this?\n",
    "\n",
    "We have to create set of instances from which our model will learn.\n",
    "\n",
    "Think on the learning task. What is the task that the model has to do?\n",
    "\n",
    "And then, how can we get an $X$ and a $y$ with which we will fit the model?\n",
    "\n",
    "Use the variable `data` to generate the instances ($X$) and classes ($y$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffProject G'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163817"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(data), len(char_to_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163817, 87)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeff'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concatenate the one hot encodings for bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, char in enumerate(data):\n",
    "    X[i, char_to_ix[char]] = 1 \n",
    "X[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a model\n",
    "\n",
    "Is your data ready? Perfect! Let's make it learn something now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=25,hidden_layer_sizes=(10),verbose=True)\n",
    "mlp.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the next character\n",
    "\n",
    "You can generate some text using the `mlp.predict` function. How does the text that you generate look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the probability distributions for different inputs\n",
    "\n",
    "You can also check the probability distribution of the next character, given a specific input. Use the `mlp.predict_prpoba` function for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting that probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a30cf16d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(len(mlp.classes_)),mlp.predict_proba(inst));\n",
    "np.argmax(mlp.predict_proba(inst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going deeper\n",
    "\n",
    "Now let's suppose that we make a deeper model. For example a model with three hidden layers:\n",
    "\n",
    "  - Layer 1 size: 300\n",
    "  - Layer 2 size: 40\n",
    "  - Layer 3 size: 20\n",
    "\n",
    "Which will the sizes of the weight matrices of the MLP be? Try to think a little bit on this, and make sure you understand how it works.\n",
    "\n",
    "Create a MLP that follows those specifications and set the parameter `max_iter` in $25$. Leave the other parameters as they are by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
